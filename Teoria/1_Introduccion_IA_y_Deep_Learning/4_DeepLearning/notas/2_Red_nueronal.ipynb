{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:rgb(50, 120, 229);\"> Redes Neuronales </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./images/net.png\" width=\"500\">\n",
    "</center>\n",
    "\n",
    "Estás viendo una red neuronal muy simple. Tiene una capa de entrada, una capa de salida y una capa oculta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, puede haber múltiples capas ocultas y cada capa puede tener múltiples nodos. \n",
    "\n",
    "Cada nodo en la capa es una neurona que puede considerarse como una unidad básica de procesamiento de una red neuronal. También se le llama **perceptrón**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./images/net_layers.png\" width=\"500\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> Perceptrón </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos cómo se ve un neurona básica o un perceptrón. Puedes ver que tenemos una serie de entradas $x_1$, $x_2$, $x_n$. \n",
    "\n",
    "Funciona en dos pasos: primero calcula la suma ponderada de sus entradas, tenemos estos pesos $w_1$, $w_2$, $w_n$, que se multiplican con la entrada correspondiente y luego se suman esas entradas ponderadas. \n",
    "\n",
    "Luego, se agrega un término de sesgo que se representa usando b y, finalmente, se aplica una transformación no lineal llamada función de activación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./images/perceptron_body.png\" width=\"500\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitivamente, cada neurona está buscando un patrón particular presente en la capa anterior. Si encuentra el patrón, produce una salida alta o, en otras palabras, se activa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> Función de Activación </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una función de activación se utiliza como una función de toma de decisiones en la salida de una neurona. La neurona aprende límites de decisión lineales o no lineales basados en esta función de activación. \n",
    "\n",
    "Debe tenerse en cuenta que dado que todas las neuronas simplemente realizan sumas ponderadas, que es una **operación lineal**, la salida siempre será lineal independientemente de cuántas capas o nodos agreguemos. \n",
    "\n",
    "La función de activación tiene el efecto de agregar no linealidad a este sistema de lo contrario lineal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> Funciones de Activación populares </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./images/activation_functions.png\" width=\"1200\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> Arquitectura de Redes Neuronales </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> **Capa de entrada** </font>\n",
    "\n",
    "Cada red neuronal tiene una capa de entrada. Esta es la primera capa de la red neuronal y se utiliza para proporcionar los datos de entrada o características a la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> **Capa de salida** </font>\n",
    "\n",
    "Esta capa emite nuestras predicciones. **La función de activación que usamos en esta capa es diferente para diferentes problemas.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> **Capas ocultas** </font>\n",
    "\n",
    "La red neuronal aplica una serie de funciones a la entrada. Al tener múltiples capas ocultas, podemos calcular funciones complejas al encadenar funciones más simples.\n",
    "\n",
    "\n",
    "Supongamos que queremos calcular la séptima potencia de un número, pero queremos mantener las cosas simples para que sean fáciles de entender e implementar. Por lo tanto, podemos usar potencias más simples como cuadrados y cubos para calcular las funciones de orden superior.\n",
    "\n",
    "$$x^7 = x^2 + x^2 + x^3$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera similar, puedes calcular funciones altamente complejas mediante este efecto en cascada. \n",
    "\n",
    "La unidad oculta más ampliamente utilizada es aquella que utiliza una unidad lineal rectificada (ReLU) como función de activación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> Redes Neuronales Profundas </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El número de capas ocultas se denomina como la profundidad de la red neuronal y es posible que te hagas la pregunta: ¿cuántas capas debería tener exactamente una red neuronal? \n",
    "\n",
    "No hay una respuesta correcta a esto. Por lo general, cuando tenemos un problema más simple, no necesitamos redes muy profundas, pero como regla general, las redes más profundas pueden aprender funciones más complejas."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
