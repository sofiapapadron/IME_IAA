{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:rgb(50, 120, 229);\"> Auto MPG Dataset </font>\n",
    "\n",
    "En este cuaderno, estaremos trabajando con el conjunto de datos Auto MPG del repositorio de aprendizaje automático de UC Irvine aquí. \n",
    "\n",
    "Este conjunto de datos contiene casi 400 muestras de datos de automóviles de la década de 1970. Hay ocho campos de datos en el conjunto de datos que consisten en varios atributos como el peso del vehículo y la potencia, y el objetivo es utilizar estas características para predecir el consumo de combustible del vehículo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 8)\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> 1. Cargar los datos </font>\n",
    "\n",
    "Los datos se encuentran en formato CSV, por lo que podemos cargarlos fácilmente utilizando la biblioteca pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/auto-mpg.csv')\n",
    "data = data[[\"MPG\", \"Displacement\", \"Horsepower\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> 2. Limpieza de datos </font>\n",
    "\n",
    "La mayoría de los conjuntos de datos requieren algún nivel de preprocesamiento, a menudo denominado \"limpieza\". \n",
    "\n",
    "Por ejemplo, algunos campos pueden faltar en campos numéricos etiquetados en el conjunto de datos con varios marcadores ('?', 'N/A', 'NaN', etc.). Para verificar esta condición, podemos usar el siguiente comando.\n",
    "\n",
    "<font style=\"color:rgb(8, 133, 37);\">**Sintaxis:**</font>\n",
    "\n",
    "```python\n",
    "df.isna().sum()\n",
    "```\n",
    "\n",
    "Esto nos dará una lista de todas las columnas y la cantidad de valores faltantes en cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Muestra el número de datos faltantes en cada columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes observar que tenemos 6 valores faltantes en la columna 'horsepower'. \n",
    "\n",
    "Existen diferentes estrategias para manejar los valores faltantes, en este ejercicio eliminaremos las filas que contienen valores faltantes.\n",
    "\n",
    "<font style=\"color:rgb(8, 133, 37);\">**Sintaxis:**</font>\n",
    "\n",
    "```python\n",
    "df = df.dropna()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Elimina las filas con datos faltantes\n",
    "\n",
    "#TODO: Muestra el número de datos faltantes en cada columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> 3. Análisis exploratorio de datos </font>\n",
    "\n",
    "El análisis exploratorio de datos es una parte importante de cualquier proyecto de aprendizaje automático. Nos ayuda a comprender mejor los datos y a identificar patrones y relaciones entre las diferentes características. Esto queda fuera del alcance de este cuaderno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> 4. Revisar las estadísticas de los datos </font>\n",
    "\n",
    "Podemos usar el método `describe()` para obtener un resumen de las estadísticas de los datos.\n",
    "\n",
    "<font style=\"color:rgb(8, 133, 37);\">**Sintaxis:**</font>\n",
    "\n",
    "```python\n",
    "df.describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Muestra las estadísticas básicas de las columnas numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver en la tabla, las diversas características tienen un amplio rango de valores que abarcan tres órdenes de magnitud. Cuando los datos de las características varían tan ampliamente, generalmente se recomienda escalar los datos de las características como un paso de preprocesamiento antes de entrenar un modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> 5. Dividir los datos en conjuntos de entrenamiento y prueba </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a dividir el conjunto de datos en componentes de prueba y entrenamiento, lo cual es necesario para entrenar y probar adecuadamente los modelos.\n",
    "\n",
    "<font style=\"color:rgb(8, 133, 37);\">**Sintaxis:**</font>\n",
    "\n",
    "```python\n",
    "train_df = df.sample(frac=0.8, random_state=0)\n",
    "test_df = df.drop(train_df.index)\n",
    "```\n",
    "\n",
    "**Parámetros:**\n",
    "\n",
    "- `frac`: Fracción de los datos que se utilizarán para el conjunto de entrenamiento.\n",
    "- `random_state`: Semilla para la generación de números aleatorios. (Se utiliza para reproducir los mismos resultados).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Separa los datos en entrenamiento y prueba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> 6. Separar las características y las etiquetas </font>\n",
    "\n",
    "Dado que las características y el valor objetivo están contenidos en el mismo marco de datos, los separaremos en dos marcos de datos para mantenerlos aislados. Esto también facilita la gestión de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(8, 133, 37);\">**Sintaxis:**</font>\n",
    "\n",
    "```python\n",
    "train_features = train_df.copy() # Copiar todas las columnas\n",
    "test_features = test_df.copy()\n",
    "```\n",
    "\n",
    "```python\n",
    "train_labels = train_features.pop('mpg') # Eliminar la columna 'mpg' de train_features y almacenarla en train_labels\n",
    "test_labels = test_features.pop('mpg') \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Crea una copia de los datos de entrenamiento y prueba\n",
    "\n",
    "\n",
    "#TODO: Separa las etiquetas de los datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(8, 133, 37);\">**Convertir a numpy array:**</font>\n",
    "\n",
    "Keras espera que los datos de entrada sean matrices numpy, por lo que necesitamos convertir los datos de entrenamiento y prueba en matrices numpy.\n",
    "\n",
    "```python\n",
    "X_train = train_features.values\n",
    "X_test = test_features.values\n",
    "\n",
    "y_train = train_labels.values\n",
    "y_test = test_labels.values\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Convierte los datos a arreglos de numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> 6. Normalización de datos </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se mencionó anteriormente, este conjunto de datos contiene una amplia gama de valores de características, y a menudo se recomienda escalar las características para que abarquen un rango de valores similar. \n",
    "\n",
    "Una razón por la que esto es importante es que las características se multiplican por los pesos del modelo. Por lo tanto, la escala de las salidas y la escala de los gradientes se ven afectadas por la escala de las entradas. \n",
    "\n",
    "Aunque un modelo podría converger sin escalar las características, el escalado de las características hace que el entrenamiento sea mucho más estable y también facilita el proceso de optimización al permitir que el descenso de gradiente converja mucho más rápido.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\">**Estándarización**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estandarización (también conocida como escalado de puntuación z) asume que los datos originales están distribuidos de forma normal y escala la característica para que tenga una media de cero y una desviación estándar de 1. \n",
    "\n",
    "Esto se logra para cada característica (xi) restando la media de los datos de la característica a cada punto de datos (conocido como sustracción de la media) y luego dividiendo ese resultado por la desviación estándar de los datos de la característica, como se muestra a continuación:\n",
    "\n",
    "$$\n",
    "x_i = \\frac{x_i - \\text{mean}(x)}{\\text{std}(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(196, 30, 58);\">**NOTA**</font>\n",
    "\n",
    "Los parámetros de normalización (media y desviación estándar) se derivan solo del conjunto de datos de entrenamiento, pero se aplicarán a todos los datos (entrenamiento, validación y prueba).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Normaliza los datos de entrenamiento y prueba creando una capa de Normalización\n",
    "#Se utiliza train_features para normalizar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> 7. Construir el modelo </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> 7.1. Definir el modelo </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"./images/auto-model.webp\" width=600/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Define un modelo con dos capas ocultas con 32 neuronas y su capa de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> 7.2. Definir la función de pérdida y el optimizador </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos la función de pérdida de error cuadrático medio (mse) y el optimizador SDG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Compila el modelo con la función de pérdida y el optimizador adecuado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> 7.3. Entrenar el modelo </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de entrenar el modelo usando la única característica de entrada. \n",
    "\n",
    "Para este conjunto de datos y los ejemplos en este cuaderno, usaremos 100 épocas. \n",
    "\n",
    "Especifica un `validación_split` del 30% (0.3), para reservar el 30% de las muestras de entrenamiento para no ser utilizadas para entrenar el modelo, de modo que puedan ser utilizadas para evaluar el modelo durante el proceso de entrenamiento.\n",
    "\n",
    "**Más adelante entenderemos por que esto es importante**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Utiliza el método fit para entrenar el modelo, guarda el historial del entrenamiento en la variable history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante este entrenamiento guardaremos dos historiales: \n",
    "\n",
    "- La pérdida de entrenamiento en cada época.\n",
    "- La pérdida de validación en cada época. (Después de ajustar los pesos del modelo, evaluamos el modelo en el conjunto de validación para ver cómo se desempeña en datos no vistos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Grafica la pérdida en función del número de épocas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> 7.4. Evaluar el modelo </font>\n",
    "\n",
    "Finalmente, evaluaremos el modelo en el conjunto de prueba y veremos cómo se desempeña en datos no vistos.\n",
    "\n",
    "Para evaluar el modelo, utilizaremos la función `evaluate()` que devolverá la pérdida y las métricas del modelo.\n",
    "\n",
    "```python\n",
    "model.evaluate(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Evalúa el modelo con los datos de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> 7.4. Visualizar resultados </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecuta las siguientes celdas para visualizar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_min = train_features.Horsepower.min()\n",
    "hp_max = train_features.Horsepower.max()\n",
    "dp_min = train_features.Displacement.min()\n",
    "dp_max = train_features.Displacement.max()\n",
    "\n",
    "x_surf, y_surf = np.meshgrid(np.linspace(hp_min, hp_max, 100), np.linspace(dp_min, dp_max, 100))\n",
    "x_grid = pd.DataFrame({'Horsepower': x_surf.ravel(), 'Displacement': y_surf.ravel()})\n",
    "\n",
    "pred_y = model.predict(x_grid)\n",
    "pred_y = np.array(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], y_train, c='green',  marker='o', alpha=0.5)\n",
    "ax.plot_surface(x_surf, y_surf, pred_y.reshape(x_surf.shape), color='blue', alpha=0.5)\n",
    "ax.set_xlabel('Horsepower')\n",
    "ax.set_ylabel('Displacement')\n",
    "ax.set_zlabel('MPG')\n",
    "ax.view_init(8, -40)\n",
    "\n",
    "ax = fig.add_subplot(122, projection='3d')\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], y_train, c='green',  marker='o', alpha=0.5)\n",
    "ax.plot_surface(x_surf, y_surf, pred_y.reshape(x_surf.shape), color='blue', alpha=0.5)\n",
    "ax.set_xlabel('Horsepower')\n",
    "ax.set_ylabel('Displacement')\n",
    "ax.set_zlabel('MPG')\n",
    "ax.view_init(8, 130)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
