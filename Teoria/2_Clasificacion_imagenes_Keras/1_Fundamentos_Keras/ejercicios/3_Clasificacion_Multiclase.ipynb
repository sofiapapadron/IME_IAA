{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color: rgb(50, 120, 229);\"> Clasificación Multiclase en Keras </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este cuaderno, introduciremos varios conceptos nuevos asociados con el problema general de clasificación que implica más de dos clases. \n",
    "\n",
    "Específicamente, en este cuaderno, veremos cómo clasificar dígitos escritos a mano de la base de datos MNIST. El conjunto de datos MNIST está incluido en Tensorflow y se puede importar y cargar fácilmente, como veremos a continuación. \n",
    "\n",
    "Usando este conjunto de datos, demostraremos cómo trabajar con datos de imágenes que representan los dígitos $[0,9]$ y cómo desarrollar una arquitectura de red que incluya diez neuronas cuyas salidas representen la probabilidad de los dígitos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/mnist.png\" width=\"600\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (28, 28)\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color: rgb(50, 120, 229);\"> 1. Cargar el conjunto de datos MNIST </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se discutió anteriormente, utilizaremos los datos de MNIST para nuestro experimento. Contiene `60000` imágenes de entrenamiento en escala de grises `28x28` y `10000` imágenes de prueba de `10` clases.\n",
    "\n",
    "El conjunto de datos MNIST **ya viene incluido con Keras**. PyTorch proporciona acceso fácil a algunos conjuntos de datos estándar utilizando `keras.datasets`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color: rgb(50, 120, 229);\"> 1.1 Descargar el conjunto de datos </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de entrenamiento y pruebas por separado.s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color: rgb(50, 120, 229);\"> 1.2 Visualizar algunas imágenes </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora mostraremos una muestra de los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 16\n",
    "num_cols = 4\n",
    "num_rows = num_samples // num_cols\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    image = X_train[i]\n",
    "    label = y_train[i]\n",
    "\n",
    "    plt.subplot(num_rows, num_cols, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Label: {label}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color: rgb(50, 120, 229);\"> 1.3 Preprocesamiento de datos </font>\n",
    "\n",
    "Antes de comenzar a entrenar la red, necesitamos aplicar algunas transformaciones a los datos.\n",
    "\n",
    "**Cambiar la forma de los datos**: \n",
    " \n",
    "Dado que ahora estamos trabajando con una imagen como entrada, necesitamos encontrar una forma lógica de representar los datos de la imagen como un conjunto de características. Un enfoque ingenuo que en realidad funciona bastante bien es simplemente asumir que las intensidades de píxeles son las características. \n",
    "\n",
    "Una forma de transformar los datos de la imagen en un conjunto de características que podemos procesar es aplanar la matriz 2D en una matriz 1D. La imagen de entrada de 28x28 se convierte así en una matriz 1D que contiene 784 características.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Cambia la forma de los datos de entrada para que tengan la forma (n, 784), puedes usar la función reshape de numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Normalización**: Normalizamos los valores de píxeles de las imágenes en el rango `[0, 1]` dividiendo cada píxel por `255.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Normaliza los datos de entrada, si es necesario cambia el tipo de los datos a float32 con astype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Codificación One-hot**: Convertimos las etiquetas en un formato que pueda ser utilizado por la red neuronal. Para hacer esto, usamos la función `to_categorical` de Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "#TODO: Convierte las etiquetas a one-hot encoding, envia como argumento las etiquetas y el número de clases (NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color: rgb(50, 120, 229);\"> 2. Arquitectura de la red neuronal </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color: rgb(50, 120, 229);\"> 2.1 Perceptrón de una capa </font>\n",
    "\n",
    "La arquitectura de red mostrada a continuación es similar a la arquitectura anterior para clasificación binaria, pero con algunas diferencias importantes. Las diferencias clave se resumen a continuación:\n",
    "\n",
    "1. Los datos de entrada de la imagen se preprocesan de una manera que aún no hemos discutido (más sobre esto a continuación).\n",
    "2. Ahora tenemos 10 neuronas para representar las diez clases diferentes (dígitos: 0 a 9), en lugar de una sola neurona como con la clasificación binaria.\n",
    "3. La función de activación es una activación de **softmax** en lugar de una activación sigmoidea.\n",
    "4. La función de pérdida es ahora la **entropía cruzada categórica**.\n",
    "\n",
    "Aunque el diagrama parece bastante diferente de las arquitecturas anteriores (una sola neurona), es muy similar en términos del procesamiento que se lleva a cabo durante el entrenamiento y la predicción.\n",
    "\n",
    "<center>\n",
    "    <img src=\"./images/multiclassification_model1.jpg\" width=\"800\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color: rgb(50, 120, 229);\"> 2.2 Redes Neuronales Totalmente Conectadas </font>\n",
    "\n",
    "Las arquitecturas de redes neuronales que hemos cubierto hasta ahora en el curso han utilizado capas \"totalmente conectadas\", que también se denominan \"densas\" o \"lineales\". Esta arquitectura es muy común, pero a medida que el número de entradas y neuronas en cada capa se vuelve más grande, el número de parámetros entrenables crece exponencialmente.\n",
    "\n",
    "Cuando se representan las arquitecturas de redes neuronales con capas totalmente conectadas, las conexiones suelen omitirse con la comprensión de que se asume que 'densa' o 'totalmente conectada' está implícito.\n",
    "\n",
    "<center>\n",
    "    <img src=\"./images/fcl.webp\" width=\"600\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Crea un modelo secuencial con su capa de entrada y una capa densa de 10 neuronas con activación softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: imprime un resumen del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color: rgb(50, 120, 229);\"> 2.3 Flujo de entrenamiento </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Compila el modelo con el optimizador 'sdg', la función de pérdida 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Entrena el modelo con los datos de entrenamiento, usando 25 epochs y un batch_size de 32, guarda el historial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**:\n",
    "\n",
    "Puedes ver que incluimos el concepto de `batch_size`.\n",
    "\n",
    "El tamaño del lote es el número de muestras que se propagan a través de la red antes de que se actualicen los pesos, para entenderlo mejor, veamos un ejemplo:\n",
    "\n",
    "- El conjunto de datos de entrenamiento del MNIST tiene 60,000 imágenes.\n",
    "- Si el tamaño del lote es 32, se tomarán 32 imágenes al azar y se propagarán a través de la red, después se actualizarán los pesos.\n",
    "- Este proceso se repetirá hasta que se propaguen todas las imágenes a través de la red. Es decir hasta que se cumplan 60,000 / 32 = 1875 lotes. (Esto se conoce como una época)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color: rgb(50, 120, 229);\"> 2.4 Gráficos de pérdida y precisión </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.figure(figsize=[15, 5])\n",
    "plt.plot(epochs, loss_values, \"g\", label=\"Training loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlim(0, 50)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color: rgb(50, 120, 229);\"> 3. Guardar y cargar modelos </font>\n",
    "\n",
    "Guardar y cargar modelos es muy conveniente. Esto te permite desarrollar y entrenar un modelo, guardarlo en el sistema de archivos y luego cargarlo en algún momento futuro para su uso. \n",
    "\n",
    "En esta sección cubriremos las operaciones básicas para guardar y cargar modelos.\n",
    "\n",
    "### <font style=\"color: rgb(50, 120, 229);\"> 3.1 Guardar un modelo </font>\n",
    "\n",
    "Puedes guardar fácilmente un modelo usando el método `save()`, que guardará el modelo en el sistema de archivos en el formato 'SavedModel'. \n",
    "\n",
    "Este método crea una carpeta en el sistema de archivos. Dentro de esta carpeta, la arquitectura del modelo y la configuración de entrenamiento (incluyendo el optimizador, las pérdidas y las métricas) se almacenan en saved_model.pb. \n",
    "\n",
    "La carpeta 'variables/' contiene un punto de control estándar de entrenamiento que incluye los pesos del modelo. Profundizaremos en estos detalles en cuadernos posteriores. \n",
    "\n",
    "Por ahora, simplemente guardemos el modelo entrenado y luego lo cargaremos en la siguiente celda de código con un nombre diferente y continuaremos usándolo en el resto del cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('MNIST_classifer_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color: rgb(50, 120, 229);\"> 3.2 Cargar un modelo </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('MNIST_classifer_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color: rgb(50, 120, 229);\"> 4. Evaluación del modelo </font>\n",
    "\n",
    "Ahora podemos predecir los resultados para todas las imágenes de prueba, como se muestra en el código a continuación. \n",
    "\n",
    "Aquí, llamamos al método `predict()` para recuperar todas las predicciones, y luego seleccionamos un índice específico del conjunto de pruebas e imprimimos los puntajes predichos para cada clase. \n",
    "\n",
    "Puedes experimentar con el código a continuación estableciendo el índice de prueba en varios valores y ver cómo el puntaje más alto generalmente está asociado con el valor correcto indicado por la verdad fundamental.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "num_samples = 16\n",
    "num_cols = 4\n",
    "num_rows = num_samples // num_cols\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    image = X_test[i].reshape(28, 28)\n",
    "    pred = predictions[i]\n",
    "    pred_label = pred.argmax() # obtiene el índice de la clase con mayor probabilidad\n",
    "    real_label = y_test[i].argmax() # obtiene el índice de la clase real\n",
    "    color = 'green' if pred_label == real_label else 'red'\n",
    "\n",
    "    plt.subplot(num_rows, num_cols, i+1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f'Pred: {pred_label} \\nLabel: {real_label}', color=color)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color: rgb(50, 120, 229);\"> Preguntas de comprensión </font>\n",
    "\n",
    "1. ¿Qué es la clasificación multiclase?\n",
    "2. ¿Qué función de activación se utiliza en la capa de salida de una red neuronal en un problema de clasificación multiclase?\n",
    "3. ¿Qué me da como salida una red neuronal en un problema de clasificación multiclase?\n",
    "4. ¿Qué función de pérdida se utiliza en un problema de clasificación multiclase?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
