{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:rgb(50, 120, 229);\"> Transfer Learning  y Fine Tuning </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Learning y Fine Tuning se basan en la idea de que una red neuronal que ha sido entrenada para realizar una tarea determinada aprende características que también son importantes para resolver una tarea diferente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> **Ejemplo** </font>\n",
    "\n",
    "Para entender mejor esto veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos resolver un problema de clasificación de habitaciones. Entonces, dada una imagen de una habitación, queremos identificar si es un dormitorio, cocina o baño. \n",
    "\n",
    "Por lo tanto, tenemos tres clases y en esta situación, digamos que tenemos un conjunto de datos muy limitado. \n",
    "\n",
    "Tenemos cien ejemplos de cada clase. Por lo tanto, no tenemos muchos datos.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/problem.png\" width=\"800px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> **Selecciona un modelo pre-entrenado** </font>\n",
    "\n",
    "Como mencionamos antes, si quieres resolver un problema de clasificación, simplemente puedes elegir una red estándar. \n",
    "\n",
    "Entonces, vamos a empezar con VGG en este caso. \n",
    "\n",
    "Lo primero que necesitas hacer es quitar la última capa de VGG y reemplazarla con tres salidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La red VGG fue diseñada para resolver el desafío de reconocimiento visual a gran escala de ImageNet, por lo que tiene 1,000 clases. \n",
    "\n",
    "Por lo tanto, resuelve el problema de clasificación para 1,000 clases. Obviamente, la última capa no es relevante aquí y debemos reemplazarla con una capa completamente conectada diferente que tenga solo tres salidas en lugar de 1,000 salidas.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/vgg.png\" width=\"1200px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> **Entrenamiento** </font>\n",
    "\n",
    "Para entrenar esta red, tenemos dos opciones. La primera opción es comenzar con pesos aleatorios y usar nuestros datos para entrenar la red, pero esta no es una opción muy emocionante porque tenemos datos muy limitados. \n",
    "\n",
    "¿Hay algo mejor que podamos hacer? La respuesta es sí. Podemos comenzar con pesos no aleatorios, sino con **pesos preentrenados** que se obtuvieron entrenando la red en el conjunto de datos de ImageNet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> **¿Dónde puedo obtener estos pesos preentrenados?** </font>\n",
    "\n",
    "Podemos encontrar fácilmente pesos preentrenados que han sido entrenados por alguien más en Internet para ImageNet porque cualquier red que alguien publique generalmente proporciona los pesos preentrenados que fueron entrenados en ImageNet. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> **¿Por qué es útil comenzar con pesos preentrenados?** </font>\n",
    "\n",
    "La idea central es que las características aprendidas al entrenar con un conjunto de datos muy grande para la tarea A también son útiles para resolver una tarea B muy diferente. \n",
    "\n",
    "Y la razón es que estas características son características visuales, características de bajo nivel como bordes, puntos y cosas así, que son independientes de la tarea que está tratando de resolver.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/basic_features.png\" width=\"800px\">\n",
    "</center>\n",
    "\n",
    "Estas son características muy generales porque el conjunto de datos era tan grande que la red tuvo que aprender algunas características muy generales que son buenas para la clasificación de imágenes. \n",
    "\n",
    "Por lo tanto, no importa si lo usamos para una tarea diferente, ha aprendido características que son fundamentales. Ha aprendido a reconocer objetos e, incluso si cambiamos completamente los objetos, aún puede usar esas características para reconocer objetos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> **¿Cómo utilizamos estos pesos preentrenados?** </font>\n",
    "\n",
    "Podemos usar estos pesos preentrenados para inicializar nuestra red y luego entrenar la red en nuestro conjunto de datos.\n",
    "\n",
    "Los pesos de la parte convolucional de la red suelen **congelarse**. Esto significa que no se actualizan durante el entrenamiento, a esto se le llama **Transfer Learning**.\n",
    "\n",
    "Podemos congelar solo las primeras capas de la parte convolucional (las que aprenden características de bajo nivel) y entrenar las últimas capas de la parte convolucional y las capas completamente conectadas. A esto se le llama **Fine Tuning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> ¿Cómo elegir el mejor proceso de Transfer Learning? </font>\n",
    "\n",
    "Recuerda que las primeras capas convolucionales extraen características genéricas y se vuelven más específicas para los datos de entrenamiento a medida que avanzamos más en la red.\n",
    "\n",
    "Dicho esto, podemos elegir el nivel de detalle para la extracción de características de un modelo preentrenado existente.\n",
    "\n",
    "Discutamos estos escenarios uno por uno para aprender las reglas generales comunes para navegar nuestras opciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> Caso 1: Pocos datos y similares a los datos originales </font>\n",
    "\n",
    "Dado que el conjunto de datos original es similar a nuestro nuevo conjunto de datos, podemos esperar que las características de nivel superior en la ConvNet preentrenada sean relevantes para nuestro conjunto de datos también. \n",
    "\n",
    "Entonces, podría ser mejor congelar la parte convolucional de la red y solo volver a entrenar el clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra razón por la que podría no ser una buena idea ajustar la red es que nuestro nuevo conjunto de datos es pequeño. Si afinamos las capas de extracción de características en un conjunto de datos pequeño, eso forzará a la red a sobreajustarse a nuestros datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> Caso 2: Muchos datos y similares a los datos originales </font>\n",
    "\n",
    "Dado que ambos dominios son similares, podemos congelar la parte de extracción de características y volver a entrenar el clasificador, similar a lo que hicimos en el escenario 1. \n",
    "\n",
    "Pero dado que tenemos más datos en el nuevo dominio, podemos obtener un impulso de rendimiento al afinar toda o parte de la red preentrenada con más confianza en que no sobreajustaremos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> Caso 3: Pocos datos y diferentes a los datos originales </font>\n",
    "\n",
    "Dado que el conjunto de datos es diferente, podría no ser lo mejor congelar las características de nivel superior de la red preentrenada, porque contienen características más específicas del conjunto de datos. \n",
    "\n",
    "En su lugar, funcionaría mejor volver a entrenar las capas desde algún punto anterior en la red, o no congelar ninguna capa y afinar toda la red. Sin embargo, dado que tienes un conjunto de datos pequeño, afinar toda la red en el conjunto de datos podría no ser una buena idea, ya que esto la hará propensa al sobreajuste. Una solución intermedia funcionará mejor en este caso. \n",
    "\n",
    "Un buen comienzo es congelar aproximadamente el primer tercio o la mitad de la red preentrenada. Después de todo, las capas iniciales contienen mapas de características muy genéricas que serán útiles para tu conjunto de datos, incluso si es muy diferente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> Caso 4: Muchos datos y diferentes a los datos originales </font>\n",
    "\n",
    "Dado que el nuevo conjunto de datos es grande, podrías sentir la tentación de entrenar toda la red desde cero y no usar aprendizaje por transferencia en absoluto. \n",
    "\n",
    "Sin embargo, en la práctica, a menudo sigue siendo muy beneficioso inicializar los pesos desde un modelo preentrenado, como discutimos anteriormente. \n",
    "\n",
    "Hacer esto hace que el modelo converja más rápido.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./images/transfer_cases.png\" width=\"800px\">\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
