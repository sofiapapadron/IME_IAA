{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:rgb(50, 120, 229);\"> Fine Tuning en Keras </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el cuaderno anterior, demostramos que podíamos usar **Transfer Learning** para crear un nuevo clasificador para el conjunto de datos ASL. \n",
    "\n",
    "Sin embargo, mostramos que congelar toda la base convolucional con pesos preentrenados del entrenamiento de ImageNet no resultó en un clasificador altamente efectivo. Esto se debe al hecho de que los pesos de ImageNet no capturan algunas de las características únicas que se requieren para el conjunto de datos ASL. \n",
    "\n",
    "En este cuaderno, vamos a introducir un enfoque híbrido donde utilizamos pesos preentrenados para las primeras capas de la red (que han aprendido características más generales de ImageNet) y luego permitimos que el modelo ajuste los pesos para los bloques convolucionales subsecuentes (más las capas completamente conectadas). \n",
    "\n",
    "Este enfoque se llama **Fine-Tuning** porque realiza pequeños ajustes a las representaciones más abstractas del modelo reutilizado para hacerlas más relevantes para el problema en cuestión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./images/cnn_vgg_pretrained_small_base_ASL.webp\" width=\"800px\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**El proceso de Transfer Learning y Fine Tuning se resume a continuación:**\n",
    "\n",
    "1. Instanciar la base convolucional VGG-16 con pesos preentrenados de ImageNet.\n",
    "2. Configurar la base convolucional como \"entrenable\".\n",
    "3. Congelar todas las capas en la base convolucional (EXCEPTO las últimas cuatro).\n",
    "4. Agregar una capa clasificador densa para el conjunto de datos ASL.\n",
    "5. Entrenar el modelo (las últimas cuatro capas de la base convolucional más el clasificador denso).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> 1. Configuración inicial </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 50\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> 2. Descargar el conjunto de datos ASL </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /root/.kaggle\n",
    "!mv kaggle.json /root/.kaggle/\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/grassknoted/asl-alphabet\n",
      "License(s): GPL-2.0\n",
      "Downloading asl-alphabet.zip to c:\\Users\\97ped\\Documents\\Programacion\\deep_learning-tensorflow\\2_Clasificacion_imagenes_Keras\\4_Entrenar_CNN_Personalizadas\\ejercicios\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/1.03G [00:00<?, ?B/s]\n",
      "  0%|          | 1.00M/1.03G [00:00<03:32, 5.17MB/s]\n",
      "  0%|          | 4.00M/1.03G [00:00<01:13, 14.9MB/s]\n",
      "  1%|          | 7.00M/1.03G [00:00<00:59, 18.3MB/s]\n",
      "  1%|          | 10.0M/1.03G [00:00<00:53, 20.5MB/s]\n",
      "  1%|          | 13.0M/1.03G [00:00<00:49, 21.9MB/s]\n",
      "  2%|▏         | 16.0M/1.03G [00:00<00:47, 22.7MB/s]\n",
      "  2%|▏         | 19.0M/1.03G [00:00<00:46, 23.5MB/s]\n",
      "  2%|▏         | 22.0M/1.03G [00:01<00:44, 24.4MB/s]\n",
      "  2%|▏         | 25.0M/1.03G [00:01<00:42, 25.3MB/s]\n",
      "  3%|▎         | 28.0M/1.03G [00:01<00:41, 25.6MB/s]\n",
      "  3%|▎         | 31.0M/1.03G [00:01<00:40, 26.3MB/s]\n",
      "  3%|▎         | 34.0M/1.03G [00:01<00:39, 27.1MB/s]\n",
      "  4%|▎         | 37.0M/1.03G [00:01<00:39, 27.1MB/s]\n",
      "  4%|▍         | 40.0M/1.03G [00:01<00:38, 27.6MB/s]\n",
      "  4%|▍         | 43.0M/1.03G [00:01<00:37, 28.0MB/s]\n",
      "  4%|▍         | 46.0M/1.03G [00:01<00:36, 28.8MB/s]\n",
      "  5%|▍         | 50.0M/1.03G [00:02<00:34, 30.1MB/s]\n",
      "  5%|▌         | 54.0M/1.03G [00:02<00:33, 30.9MB/s]\n",
      "  5%|▌         | 57.0M/1.03G [00:02<00:33, 30.9MB/s]\n",
      "  6%|▌         | 60.0M/1.03G [00:02<00:33, 30.6MB/s]\n",
      "  6%|▌         | 63.0M/1.03G [00:02<00:33, 30.7MB/s]\n",
      "  6%|▋         | 67.0M/1.03G [00:02<00:32, 31.3MB/s]\n",
      "  7%|▋         | 70.0M/1.03G [00:02<00:32, 31.3MB/s]\n",
      "  7%|▋         | 74.0M/1.03G [00:02<00:32, 31.7MB/s]\n",
      "  7%|▋         | 78.0M/1.03G [00:03<00:31, 31.9MB/s]\n",
      "  8%|▊         | 82.0M/1.03G [00:03<00:31, 32.0MB/s]\n",
      "  8%|▊         | 86.0M/1.03G [00:03<00:30, 32.7MB/s]\n",
      "  9%|▊         | 90.0M/1.03G [00:03<00:30, 32.9MB/s]\n",
      "  9%|▉         | 94.0M/1.03G [00:03<00:30, 33.2MB/s]\n",
      "  9%|▉         | 98.0M/1.03G [00:03<00:30, 32.8MB/s]\n",
      " 10%|▉         | 102M/1.03G [00:03<00:31, 31.9MB/s] \n",
      " 10%|█         | 106M/1.03G [00:03<00:31, 31.4MB/s]\n",
      " 10%|█         | 109M/1.03G [00:04<00:32, 30.6MB/s]\n",
      " 11%|█         | 112M/1.03G [00:04<00:33, 29.8MB/s]\n",
      " 11%|█         | 115M/1.03G [00:04<00:33, 29.1MB/s]\n",
      " 11%|█         | 118M/1.03G [00:04<00:33, 29.3MB/s]\n",
      " 12%|█▏        | 122M/1.03G [00:04<00:31, 30.7MB/s]\n",
      " 12%|█▏        | 125M/1.03G [00:04<00:31, 30.6MB/s]\n",
      " 12%|█▏        | 128M/1.03G [00:04<00:31, 30.6MB/s]\n",
      " 13%|█▎        | 132M/1.03G [00:04<00:30, 31.1MB/s]\n",
      " 13%|█▎        | 135M/1.03G [00:04<00:31, 30.8MB/s]\n",
      " 13%|█▎        | 139M/1.03G [00:05<00:30, 31.1MB/s]\n",
      " 14%|█▎        | 142M/1.03G [00:05<00:34, 27.6MB/s]\n",
      " 14%|█▍        | 145M/1.03G [00:05<00:38, 24.4MB/s]\n",
      " 14%|█▍        | 149M/1.03G [00:05<00:35, 26.7MB/s]\n",
      " 15%|█▍        | 153M/1.03G [00:05<00:33, 28.5MB/s]\n",
      " 15%|█▍        | 157M/1.03G [00:05<00:31, 29.6MB/s]\n",
      " 15%|█▌        | 160M/1.03G [00:05<00:31, 29.9MB/s]\n",
      " 16%|█▌        | 164M/1.03G [00:06<00:30, 30.6MB/s]\n",
      " 16%|█▌        | 168M/1.03G [00:06<00:29, 31.4MB/s]\n",
      " 16%|█▋        | 172M/1.03G [00:06<00:29, 31.7MB/s]\n",
      " 17%|█▋        | 176M/1.03G [00:06<00:28, 31.9MB/s]\n",
      " 17%|█▋        | 180M/1.03G [00:06<00:28, 31.8MB/s]\n",
      " 18%|█▊        | 184M/1.03G [00:06<00:28, 32.1MB/s]\n",
      " 18%|█▊        | 188M/1.03G [00:06<00:28, 32.1MB/s]\n",
      " 18%|█▊        | 192M/1.03G [00:06<00:29, 30.0MB/s]\n",
      " 19%|█▊        | 195M/1.03G [00:07<00:29, 29.9MB/s]\n",
      " 19%|█▉        | 198M/1.03G [00:07<00:30, 29.4MB/s]\n",
      " 19%|█▉        | 201M/1.03G [00:07<00:30, 29.2MB/s]\n",
      " 19%|█▉        | 204M/1.03G [00:07<00:30, 29.1MB/s]\n",
      " 20%|█▉        | 207M/1.03G [00:07<00:30, 29.3MB/s]\n",
      " 20%|██        | 210M/1.03G [00:07<00:29, 29.5MB/s]\n",
      " 20%|██        | 213M/1.03G [00:07<00:29, 29.9MB/s]\n",
      " 21%|██        | 216M/1.03G [00:07<00:29, 30.0MB/s]\n",
      " 21%|██        | 219M/1.03G [00:07<00:28, 30.2MB/s]\n",
      " 21%|██        | 223M/1.03G [00:08<00:27, 31.1MB/s]\n",
      " 22%|██▏       | 227M/1.03G [00:08<00:27, 31.5MB/s]\n",
      " 22%|██▏       | 231M/1.03G [00:08<00:26, 32.1MB/s]\n",
      " 22%|██▏       | 235M/1.03G [00:08<00:27, 31.6MB/s]\n",
      " 23%|██▎       | 239M/1.03G [00:08<00:27, 31.3MB/s]\n",
      " 23%|██▎       | 242M/1.03G [00:08<00:27, 31.3MB/s]\n",
      " 23%|██▎       | 246M/1.03G [00:08<00:26, 31.3MB/s]\n",
      " 24%|██▍       | 250M/1.03G [00:08<00:26, 31.6MB/s]\n",
      " 24%|██▍       | 254M/1.03G [00:09<00:26, 31.8MB/s]\n",
      " 25%|██▍       | 258M/1.03G [00:09<00:26, 31.3MB/s]\n",
      " 25%|██▍       | 262M/1.03G [00:09<00:26, 31.6MB/s]\n",
      " 25%|██▌       | 266M/1.03G [00:09<00:25, 31.6MB/s]\n",
      " 26%|██▌       | 270M/1.03G [00:09<00:25, 31.6MB/s]\n",
      " 26%|██▌       | 274M/1.03G [00:09<00:25, 31.6MB/s]\n",
      " 26%|██▋       | 278M/1.03G [00:09<00:25, 32.2MB/s]\n",
      " 27%|██▋       | 282M/1.03G [00:09<00:25, 32.2MB/s]\n",
      " 27%|██▋       | 286M/1.03G [00:10<00:24, 32.6MB/s]\n",
      " 28%|██▊       | 290M/1.03G [00:10<00:25, 31.7MB/s]\n",
      " 28%|██▊       | 294M/1.03G [00:10<00:24, 31.7MB/s]\n",
      " 28%|██▊       | 298M/1.03G [00:10<00:31, 25.0MB/s]\n",
      " 29%|██▊       | 301M/1.03G [00:10<00:29, 26.3MB/s]\n",
      " 29%|██▉       | 305M/1.03G [00:10<00:27, 27.9MB/s]\n",
      " 29%|██▉       | 308M/1.03G [00:10<00:28, 27.1MB/s]\n",
      " 30%|██▉       | 311M/1.03G [00:11<00:28, 27.6MB/s]\n",
      " 30%|███       | 315M/1.03G [00:11<00:26, 28.8MB/s]\n",
      " 30%|███       | 318M/1.03G [00:11<00:26, 29.3MB/s]\n",
      " 31%|███       | 321M/1.03G [00:11<00:25, 29.7MB/s]\n",
      " 31%|███       | 325M/1.03G [00:11<00:25, 30.3MB/s]\n",
      " 31%|███▏      | 329M/1.03G [00:11<00:24, 31.0MB/s]\n",
      " 32%|███▏      | 332M/1.03G [00:11<00:24, 30.8MB/s]\n",
      " 32%|███▏      | 336M/1.03G [00:11<00:23, 31.2MB/s]\n",
      " 32%|███▏      | 340M/1.03G [00:12<00:25, 29.2MB/s]\n",
      " 33%|███▎      | 344M/1.03G [00:12<00:23, 31.8MB/s]\n",
      " 33%|███▎      | 348M/1.03G [00:12<00:22, 32.1MB/s]\n",
      " 34%|███▎      | 352M/1.03G [00:12<00:22, 32.3MB/s]\n",
      " 34%|███▍      | 356M/1.03G [00:12<00:22, 31.9MB/s]\n",
      " 34%|███▍      | 360M/1.03G [00:12<00:22, 31.9MB/s]\n",
      " 35%|███▍      | 364M/1.03G [00:12<00:22, 31.7MB/s]\n",
      " 35%|███▌      | 368M/1.03G [00:12<00:22, 31.8MB/s]\n",
      " 35%|███▌      | 372M/1.03G [00:13<00:22, 31.3MB/s]\n",
      " 36%|███▌      | 376M/1.03G [00:13<00:22, 31.5MB/s]\n",
      " 36%|███▌      | 380M/1.03G [00:13<00:22, 31.8MB/s]\n",
      " 37%|███▋      | 384M/1.03G [00:13<00:22, 31.1MB/s]\n",
      " 37%|███▋      | 388M/1.03G [00:13<00:21, 31.6MB/s]\n",
      " 37%|███▋      | 392M/1.03G [00:13<00:21, 31.8MB/s]\n",
      " 38%|███▊      | 396M/1.03G [00:13<00:22, 30.6MB/s]\n",
      " 38%|███▊      | 400M/1.03G [00:14<00:22, 30.9MB/s]\n",
      " 38%|███▊      | 404M/1.03G [00:14<00:21, 31.4MB/s]\n",
      " 39%|███▉      | 408M/1.03G [00:14<00:21, 31.6MB/s]\n",
      " 39%|███▉      | 412M/1.03G [00:14<00:20, 31.9MB/s]\n",
      " 40%|███▉      | 416M/1.03G [00:14<00:20, 31.9MB/s]\n",
      " 40%|████      | 420M/1.03G [00:14<00:20, 32.0MB/s]\n",
      " 40%|████      | 424M/1.03G [00:14<00:20, 32.5MB/s]\n",
      " 41%|████      | 428M/1.03G [00:14<00:20, 32.5MB/s]\n",
      " 41%|████      | 432M/1.03G [00:15<00:20, 32.4MB/s]\n",
      " 42%|████▏     | 436M/1.03G [00:15<00:19, 32.2MB/s]\n",
      " 42%|████▏     | 440M/1.03G [00:15<00:19, 32.3MB/s]\n",
      " 42%|████▏     | 444M/1.03G [00:15<00:19, 32.5MB/s]\n",
      " 43%|████▎     | 448M/1.03G [00:15<00:19, 32.9MB/s]\n",
      " 43%|████▎     | 452M/1.03G [00:15<00:24, 25.3MB/s]\n",
      " 43%|████▎     | 456M/1.03G [00:16<00:22, 27.2MB/s]\n",
      " 44%|████▍     | 460M/1.03G [00:16<00:21, 28.5MB/s]\n",
      " 44%|████▍     | 464M/1.03G [00:16<00:20, 29.4MB/s]\n",
      " 45%|████▍     | 468M/1.03G [00:16<00:20, 30.3MB/s]\n",
      " 45%|████▍     | 472M/1.03G [00:16<00:19, 31.2MB/s]\n",
      " 45%|████▌     | 476M/1.03G [00:16<00:19, 31.6MB/s]\n",
      " 46%|████▌     | 480M/1.03G [00:16<00:18, 31.6MB/s]\n",
      " 46%|████▌     | 484M/1.03G [00:16<00:18, 32.3MB/s]\n",
      " 46%|████▋     | 488M/1.03G [00:17<00:18, 31.8MB/s]\n",
      " 47%|████▋     | 492M/1.03G [00:17<00:18, 32.1MB/s]\n",
      " 47%|████▋     | 496M/1.03G [00:17<00:18, 30.8MB/s]\n",
      " 48%|████▊     | 499M/1.03G [00:17<00:18, 30.9MB/s]\n",
      " 48%|████▊     | 502M/1.03G [00:17<00:20, 28.5MB/s]\n",
      " 48%|████▊     | 507M/1.03G [00:17<00:17, 32.5MB/s]\n",
      " 49%|████▊     | 511M/1.03G [00:17<00:17, 32.5MB/s]\n",
      " 49%|████▉     | 515M/1.03G [00:17<00:17, 32.8MB/s]\n",
      " 49%|████▉     | 519M/1.03G [00:18<00:17, 32.7MB/s]\n",
      " 50%|████▉     | 523M/1.03G [00:18<00:16, 32.8MB/s]\n",
      " 50%|█████     | 527M/1.03G [00:18<00:16, 32.8MB/s]\n",
      " 51%|█████     | 531M/1.03G [00:18<00:16, 32.9MB/s]\n",
      " 51%|█████     | 535M/1.03G [00:18<00:16, 32.6MB/s]\n",
      " 51%|█████▏    | 539M/1.03G [00:18<00:16, 32.5MB/s]\n",
      " 52%|█████▏    | 543M/1.03G [00:18<00:16, 32.3MB/s]\n",
      " 52%|█████▏    | 547M/1.03G [00:18<00:16, 32.6MB/s]\n",
      " 52%|█████▏    | 551M/1.03G [00:19<00:16, 32.6MB/s]\n",
      " 53%|█████▎    | 555M/1.03G [00:19<00:15, 32.8MB/s]\n",
      " 53%|█████▎    | 559M/1.03G [00:19<00:15, 33.0MB/s]\n",
      " 54%|█████▎    | 563M/1.03G [00:19<00:15, 32.8MB/s]\n",
      " 54%|█████▍    | 567M/1.03G [00:19<00:15, 32.2MB/s]\n",
      " 54%|█████▍    | 571M/1.03G [00:19<00:15, 32.1MB/s]\n",
      " 55%|█████▍    | 575M/1.03G [00:19<00:15, 31.5MB/s]\n",
      " 55%|█████▌    | 579M/1.03G [00:20<00:15, 31.3MB/s]\n",
      " 55%|█████▌    | 582M/1.03G [00:20<00:15, 30.7MB/s]\n",
      " 56%|█████▌    | 585M/1.03G [00:20<00:15, 30.7MB/s]\n",
      " 56%|█████▌    | 588M/1.03G [00:20<00:16, 30.2MB/s]\n",
      " 56%|█████▋    | 591M/1.03G [00:20<00:16, 30.0MB/s]\n",
      " 57%|█████▋    | 594M/1.03G [00:20<00:16, 29.2MB/s]\n",
      " 57%|█████▋    | 597M/1.03G [00:20<00:16, 28.9MB/s]\n",
      " 57%|█████▋    | 600M/1.03G [00:20<00:16, 28.8MB/s]\n",
      " 57%|█████▋    | 603M/1.03G [00:20<00:16, 28.5MB/s]\n",
      " 58%|█████▊    | 606M/1.03G [00:21<00:20, 22.9MB/s]\n",
      " 58%|█████▊    | 609M/1.03G [00:21<00:19, 23.7MB/s]\n",
      " 58%|█████▊    | 612M/1.03G [00:21<00:18, 25.4MB/s]\n",
      " 59%|█████▊    | 615M/1.03G [00:21<00:17, 26.2MB/s]\n",
      " 59%|█████▉    | 618M/1.03G [00:21<00:17, 26.6MB/s]\n",
      " 59%|█████▉    | 621M/1.03G [00:21<00:16, 26.8MB/s]\n",
      " 59%|█████▉    | 624M/1.03G [00:21<00:16, 27.7MB/s]\n",
      " 60%|█████▉    | 627M/1.03G [00:21<00:15, 27.7MB/s]\n",
      " 60%|██████    | 630M/1.03G [00:21<00:16, 27.2MB/s]\n",
      " 60%|██████    | 633M/1.03G [00:22<00:15, 27.9MB/s]\n",
      " 61%|██████    | 636M/1.03G [00:22<00:15, 28.7MB/s]\n",
      " 61%|██████    | 639M/1.03G [00:22<00:14, 28.9MB/s]\n",
      " 61%|██████    | 642M/1.03G [00:22<00:14, 28.6MB/s]\n",
      " 61%|██████▏   | 645M/1.03G [00:22<00:15, 28.0MB/s]\n",
      " 62%|██████▏   | 648M/1.03G [00:22<00:15, 27.5MB/s]\n",
      " 62%|██████▏   | 651M/1.03G [00:22<00:14, 27.9MB/s]\n",
      " 62%|██████▏   | 654M/1.03G [00:22<00:14, 28.4MB/s]\n",
      " 63%|██████▎   | 658M/1.03G [00:23<00:14, 29.3MB/s]\n",
      " 63%|██████▎   | 661M/1.03G [00:23<00:13, 29.3MB/s]\n",
      " 63%|██████▎   | 664M/1.03G [00:23<00:13, 29.4MB/s]\n",
      " 64%|██████▎   | 668M/1.03G [00:23<00:13, 30.8MB/s]\n",
      " 64%|██████▍   | 672M/1.03G [00:23<00:12, 31.6MB/s]\n",
      " 64%|██████▍   | 676M/1.03G [00:23<00:12, 31.8MB/s]\n",
      " 65%|██████▍   | 680M/1.03G [00:23<00:12, 32.0MB/s]\n",
      " 65%|██████▌   | 684M/1.03G [00:23<00:11, 32.6MB/s]\n",
      " 66%|██████▌   | 688M/1.03G [00:23<00:11, 32.6MB/s]\n",
      " 66%|██████▌   | 692M/1.03G [00:24<00:11, 32.4MB/s]\n",
      " 66%|██████▋   | 696M/1.03G [00:24<00:11, 31.8MB/s]\n",
      " 67%|██████▋   | 700M/1.03G [00:24<00:12, 30.4MB/s]\n",
      " 67%|██████▋   | 703M/1.03G [00:24<00:12, 30.1MB/s]\n",
      " 67%|██████▋   | 706M/1.03G [00:24<00:11, 30.2MB/s]\n",
      " 68%|██████▊   | 709M/1.03G [00:24<00:11, 30.2MB/s]\n",
      " 68%|██████▊   | 712M/1.03G [00:24<00:11, 30.2MB/s]\n",
      " 68%|██████▊   | 716M/1.03G [00:24<00:11, 30.7MB/s]\n",
      " 68%|██████▊   | 719M/1.03G [00:25<00:11, 30.4MB/s]\n",
      " 69%|██████▉   | 722M/1.03G [00:25<00:11, 30.3MB/s]\n",
      " 69%|██████▉   | 725M/1.03G [00:25<00:11, 30.6MB/s]\n",
      " 69%|██████▉   | 728M/1.03G [00:25<00:11, 29.9MB/s]\n",
      " 70%|██████▉   | 731M/1.03G [00:25<00:11, 30.2MB/s]\n",
      " 70%|██████▉   | 734M/1.03G [00:25<00:10, 30.3MB/s]\n",
      " 70%|███████   | 738M/1.03G [00:25<00:11, 27.7MB/s]\n",
      " 71%|███████   | 743M/1.03G [00:25<00:10, 31.8MB/s]\n",
      " 71%|███████   | 747M/1.03G [00:26<00:10, 30.8MB/s]\n",
      " 71%|███████▏  | 750M/1.03G [00:26<00:10, 30.8MB/s]\n",
      " 72%|███████▏  | 753M/1.03G [00:26<00:12, 25.7MB/s]\n",
      " 72%|███████▏  | 756M/1.03G [00:26<00:12, 24.5MB/s]\n",
      " 72%|███████▏  | 760M/1.03G [00:26<00:11, 27.0MB/s]\n",
      " 73%|███████▎  | 764M/1.03G [00:26<00:10, 28.5MB/s]\n",
      " 73%|███████▎  | 767M/1.03G [00:26<00:10, 29.0MB/s]\n",
      " 73%|███████▎  | 771M/1.03G [00:27<00:11, 26.2MB/s]\n",
      " 74%|███████▎  | 774M/1.03G [00:27<00:13, 21.2MB/s]\n",
      " 74%|███████▍  | 778M/1.03G [00:27<00:11, 24.2MB/s]\n",
      " 74%|███████▍  | 781M/1.03G [00:27<00:11, 23.9MB/s]\n",
      " 75%|███████▍  | 784M/1.03G [00:27<00:11, 24.5MB/s]\n",
      " 75%|███████▍  | 787M/1.03G [00:27<00:11, 24.9MB/s]\n",
      " 75%|███████▌  | 790M/1.03G [00:27<00:10, 25.5MB/s]\n",
      " 76%|███████▌  | 793M/1.03G [00:27<00:10, 25.9MB/s]\n",
      " 76%|███████▌  | 796M/1.03G [00:28<00:10, 26.6MB/s]\n",
      " 76%|███████▌  | 799M/1.03G [00:28<00:09, 26.7MB/s]\n",
      " 76%|███████▋  | 802M/1.03G [00:28<00:09, 26.6MB/s]\n",
      " 77%|███████▋  | 805M/1.03G [00:28<00:10, 24.1MB/s]\n",
      " 77%|███████▋  | 809M/1.03G [00:28<00:08, 28.4MB/s]\n",
      " 77%|███████▋  | 812M/1.03G [00:28<00:08, 28.7MB/s]\n",
      " 78%|███████▊  | 815M/1.03G [00:28<00:08, 28.4MB/s]\n",
      " 78%|███████▊  | 818M/1.03G [00:28<00:08, 28.1MB/s]\n",
      " 78%|███████▊  | 821M/1.03G [00:29<00:08, 27.9MB/s]\n",
      " 78%|███████▊  | 824M/1.03G [00:29<00:08, 27.3MB/s]\n",
      " 79%|███████▉  | 827M/1.03G [00:29<00:08, 27.6MB/s]\n",
      " 79%|███████▉  | 830M/1.03G [00:29<00:08, 27.7MB/s]\n",
      " 79%|███████▉  | 833M/1.03G [00:29<00:08, 28.2MB/s]\n",
      " 80%|███████▉  | 836M/1.03G [00:29<00:08, 28.0MB/s]\n",
      " 80%|███████▉  | 839M/1.03G [00:29<00:08, 27.6MB/s]\n",
      " 80%|████████  | 842M/1.03G [00:29<00:08, 25.6MB/s]\n",
      " 81%|████████  | 846M/1.03G [00:29<00:07, 27.7MB/s]\n",
      " 81%|████████  | 849M/1.03G [00:30<00:07, 28.1MB/s]\n",
      " 81%|████████  | 852M/1.03G [00:30<00:07, 27.9MB/s]\n",
      " 82%|████████▏ | 856M/1.03G [00:30<00:06, 29.5MB/s]\n",
      " 82%|████████▏ | 859M/1.03G [00:30<00:06, 29.8MB/s]\n",
      " 82%|████████▏ | 863M/1.03G [00:30<00:06, 30.7MB/s]\n",
      " 83%|████████▎ | 867M/1.03G [00:30<00:06, 31.6MB/s]\n",
      " 83%|████████▎ | 871M/1.03G [00:30<00:05, 31.7MB/s]\n",
      " 83%|████████▎ | 875M/1.03G [00:30<00:05, 32.2MB/s]\n",
      " 84%|████████▎ | 879M/1.03G [00:31<00:05, 32.4MB/s]\n",
      " 84%|████████▍ | 883M/1.03G [00:31<00:05, 31.8MB/s]\n",
      " 84%|████████▍ | 887M/1.03G [00:31<00:05, 33.0MB/s]\n",
      " 85%|████████▍ | 891M/1.03G [00:31<00:05, 28.6MB/s]\n",
      " 85%|████████▌ | 894M/1.03G [00:31<00:06, 25.5MB/s]\n",
      " 86%|████████▌ | 898M/1.03G [00:31<00:05, 27.4MB/s]\n",
      " 86%|████████▌ | 901M/1.03G [00:31<00:05, 28.3MB/s]\n",
      " 86%|████████▌ | 905M/1.03G [00:32<00:05, 29.3MB/s]\n",
      " 86%|████████▋ | 908M/1.03G [00:32<00:05, 29.7MB/s]\n",
      " 87%|████████▋ | 912M/1.03G [00:32<00:05, 28.7MB/s]\n",
      " 87%|████████▋ | 915M/1.03G [00:32<00:05, 25.4MB/s]\n",
      " 87%|████████▋ | 918M/1.03G [00:32<00:06, 20.6MB/s]\n",
      " 88%|████████▊ | 922M/1.03G [00:32<00:05, 23.6MB/s]\n",
      " 88%|████████▊ | 925M/1.03G [00:32<00:05, 23.0MB/s]\n",
      " 88%|████████▊ | 928M/1.03G [00:33<00:05, 23.8MB/s]\n",
      " 89%|████████▊ | 931M/1.03G [00:33<00:05, 22.2MB/s]\n",
      " 89%|████████▉ | 934M/1.03G [00:33<00:05, 23.4MB/s]\n",
      " 89%|████████▉ | 937M/1.03G [00:33<00:04, 24.3MB/s]\n",
      " 90%|████████▉ | 940M/1.03G [00:33<00:04, 24.6MB/s]\n",
      " 90%|████████▉ | 943M/1.03G [00:33<00:04, 26.1MB/s]\n",
      " 90%|█████████ | 946M/1.03G [00:33<00:04, 27.2MB/s]\n",
      " 90%|█████████ | 949M/1.03G [00:34<00:05, 20.0MB/s]\n",
      " 91%|█████████ | 954M/1.03G [00:34<00:03, 26.4MB/s]\n",
      " 91%|█████████ | 957M/1.03G [00:34<00:03, 27.3MB/s]\n",
      " 91%|█████████▏| 960M/1.03G [00:34<00:03, 27.9MB/s]\n",
      " 92%|█████████▏| 963M/1.03G [00:34<00:03, 27.8MB/s]\n",
      " 92%|█████████▏| 966M/1.03G [00:34<00:03, 27.3MB/s]\n",
      " 92%|█████████▏| 969M/1.03G [00:34<00:03, 28.0MB/s]\n",
      " 93%|█████████▎| 972M/1.03G [00:34<00:02, 28.5MB/s]\n",
      " 93%|█████████▎| 975M/1.03G [00:34<00:02, 27.6MB/s]\n",
      " 93%|█████████▎| 978M/1.03G [00:35<00:02, 27.9MB/s]\n",
      " 93%|█████████▎| 981M/1.03G [00:35<00:02, 27.9MB/s]\n",
      " 94%|█████████▎| 984M/1.03G [00:35<00:02, 27.7MB/s]\n",
      " 94%|█████████▍| 987M/1.03G [00:35<00:02, 28.4MB/s]\n",
      " 94%|█████████▍| 990M/1.03G [00:35<00:02, 28.3MB/s]\n",
      " 95%|█████████▍| 993M/1.03G [00:35<00:02, 27.9MB/s]\n",
      " 95%|█████████▍| 996M/1.03G [00:35<00:02, 27.8MB/s]\n",
      " 95%|█████████▌| 999M/1.03G [00:35<00:01, 28.7MB/s]\n",
      " 95%|█████████▌| 0.98G/1.03G [00:35<00:01, 29.3MB/s]\n",
      " 96%|█████████▌| 0.98G/1.03G [00:36<00:01, 29.2MB/s]\n",
      " 96%|█████████▌| 0.98G/1.03G [00:36<00:01, 29.1MB/s]\n",
      " 96%|█████████▋| 0.99G/1.03G [00:36<00:01, 29.0MB/s]\n",
      " 97%|█████████▋| 0.99G/1.03G [00:36<00:01, 30.3MB/s]\n",
      " 97%|█████████▋| 1.00G/1.03G [00:36<00:01, 31.0MB/s]\n",
      " 97%|█████████▋| 1.00G/1.03G [00:36<00:01, 28.8MB/s]\n",
      " 98%|█████████▊| 1.00G/1.03G [00:36<00:01, 24.0MB/s]\n",
      " 98%|█████████▊| 1.00G/1.03G [00:36<00:00, 25.1MB/s]\n",
      " 98%|█████████▊| 1.01G/1.03G [00:37<00:00, 25.9MB/s]\n",
      " 98%|█████████▊| 1.01G/1.03G [00:37<00:00, 26.1MB/s]\n",
      " 99%|█████████▉| 1.01G/1.03G [00:37<00:00, 26.0MB/s]\n",
      " 99%|█████████▉| 1.02G/1.03G [00:37<00:00, 24.0MB/s]\n",
      " 99%|█████████▉| 1.02G/1.03G [00:37<00:00, 25.3MB/s]\n",
      "100%|█████████▉| 1.02G/1.03G [00:37<00:00, 25.5MB/s]\n",
      "100%|█████████▉| 1.02G/1.03G [00:37<00:00, 25.9MB/s]\n",
      "100%|██████████| 1.03G/1.03G [00:37<00:00, 29.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d grassknoted/asl-alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q asl-alphabet.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> 3. Cargar el conjunto de datos ASL </font>\n",
    "\n",
    "El conjunto de datos ASL tiene la siguiente estructura de directorios:\n",
    "\n",
    "```bash\n",
    "dataset_ASL_150/\n",
    "    |______ A/\n",
    "    |______ B/\n",
    "    |______ C/\n",
    "    |______ D/\n",
    "    |______ E/\n",
    "    |______ F/\n",
    "    |______ G/\n",
    "    |______ H/\n",
    "    |______ I/\n",
    "    |______ J/\n",
    "    |______ K/\n",
    "    |______ L/\n",
    "    |______ M/\n",
    "    |______ N/\n",
    "    |______ O/\n",
    "    |______ P/\n",
    "    |______ Q/\n",
    "    |______ R/\n",
    "    |______ S/\n",
    "    |______ T/\n",
    "    |______ U/\n",
    "    |______ V/\n",
    "    |______ W/\n",
    "    |______ X/\n",
    "    |______ Y/\n",
    "    |______ Z/\n",
    "    |______ del/\n",
    "    |______ nothing/\n",
    "    |______ space/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import image_dataset_from_directory\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    \"./dataset_ASL_150/\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = image_dataset_from_directory(\n",
    "    \"./dataset_ASL_150/\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        label = np.argmax(labels[i])\n",
    "        class_name = class_names[label]\n",
    "        plt.title(class_name)\n",
    "        plt.axis(\"off\")\n",
    "    break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> 4. Crea el modelo </font>\n",
    "\n",
    "<font style=\"color:rgb(50, 120, 229);\"> ¿Cómo aplicar Fine Tuning en Keras? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El enfoque general para el **Fine Tuning** de una base convolucional es primero cargar los pesos preentrenados para el modelo y luego permitir selectivamente que las últimas capas convolucionales de la base sean **entrenables**. \n",
    "\n",
    "El proceso de especificar selectivamente qué capas son entrenables y cuáles no a menudo se denomina congelar o descongelar capas mediante el atributo **`trainable`** del modelo. \n",
    "\n",
    "En la figura siguiente, mostramos que la base convolucional se ha cargado con pesos preentrenados de ImageNet. \n",
    "\n",
    "\n",
    "Luego \"congelamos\" la primera parte de la base convolucional para preservar las características aprendidas de ImageNet, pero permitimos que las últimas cuatro capas se ajusten durante el proceso de entrenamiento. \n",
    "\n",
    "Usamos el término \"Fine Tuning\" en este contexto porque esperamos que las últimas capas de la base convolucional (preentrenada en ImageNet) contengan representaciones de características que son \"bastante buenas\", pero que requieren una mayor afinación para ser más relevantes para el conjunto de datos ASL.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/cnn_vgg_pretrained_fine_tune.png\" width=\"600px\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> ¿Cuál es la forma correcta de hacer Fine Tuning? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idealmente, deberías entrenar primero las capas densas (manteniendo toda la base convolucional congelada) como hicimos en el caso de \"Transfer Learning\" y luego comenzar a ajustar las capas convolucionales a una tasa de aprendizaje más baja.\n",
    "\n",
    "Sin embargo, para mantener las cosas simples en este ejemplo, entrenaremos el modelo solo una vez, lo que incluirá las últimas capas de la base convolucional así como el clasificador denso.\n",
    "\n",
    "En la práctica, al ajustar un modelo, es mejor comenzar con Fine Tuning de solo unas pocas capas a la vez para ver cómo responde el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> 4.1 Cargar la base convolucional VGG16 con pesos preentrenados </font>\n",
    "\n",
    "Comenzamos creando un modelo de la base convolucional VGG-16. Podemos hacer esto instanciando el modelo y configurando `include_top = False`, lo que excluye las capas completamente conectadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.models import Model \n",
    "from keras.layers import Dense, Flatten, Input\n",
    "\n",
    "base_model = VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    ")\n",
    "\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> 4.2 Descongelar las últimas capas de la base convolucional </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuramos el atributo `trainable` de la base convolucional a `True`. Esto ahora nos permite \"congelar\" un número seleccionado de capas en la base convolucional para que solo las últimas capas de la base convolucional sean entrenables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers_fine_tune = 4\n",
    "num_layers = len(base_model.layers)\n",
    "\n",
    "for layer in base_model.layers[:num_layers - num_layers_fine_tune]:\n",
    "    print(f\"Layer {layer.name} will be frozen\")\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> 4.3 Agregar un clasificador</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que pretendemos entrenar y usar el modelo para clasificar señales de mano del conjunto de datos ASL (que tiene 29 clases), necesitaremos agregar nuestra propia capa de clasificación. \n",
    "\n",
    "En este ejemplo, hemos elegido usar solo una capa densa completamente conectada que contiene 256 nodos, seguida de una capa de salida softmax que contiene 29 nodos, uno para cada una de las 29 clases. \n",
    "\n",
    "El número de capas densas y el número de nodos por capa es una elección de diseño, pero el número de nodos en la capa de salida debe coincidir con el número de clases en el conjunto de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "input_layer = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "x = preprocess_input(input_layer)\n",
    "x = base_model(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "\n",
    "output_layer = Dense(29, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> 4.4 Compilar y entrenar el modelo </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    \"best_model.keras\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> 5. Gráficos de pérdida y precisión </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> 6. Predicciones </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"best_model.keras\")\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "for images, labels in validation_dataset.take(1):\n",
    "    predictions = model.predict(images)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    for i in range(24):\n",
    "        image = images[i]\n",
    "        prediction = predictions[i].argmax()\n",
    "        label = labels[i].numpy().argmax()\n",
    "\n",
    "        pred_class_name = class_names[prediction]\n",
    "        label_class_name = class_names[label]\n",
    "        plt.subplot(4, 6, i + 1)\n",
    "        plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "        plt.title(f\"Prediction: {pred_class_name}, Label: {label_class_name}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    break\n",
    "\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a mostrar la matriz de confusión para ver cómo se desempeña el modelo en el conjunto de datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import TrueNegatives, TruePositives, FalseNegatives, FalsePositives\n",
    "\n",
    "# Create a confusion matrix\n",
    "tn = TrueNegatives()\n",
    "tp = TruePositives()\n",
    "fn = FalseNegatives()\n",
    "fp = FalsePositives()\n",
    "\n",
    "\n",
    "for images, labels in validation_dataset:\n",
    "    predictions = model.predict(images)\n",
    "    tn.update_state(labels, predictions)\n",
    "    tp.update_state(labels, predictions)\n",
    "    fn.update_state(labels, predictions)\n",
    "    fp.update_state(labels, predictions)\n",
    "\n",
    "print(\"True Negatives: \", tn.result().numpy())\n",
    "print(\"True Positives: \", tp.result().numpy())\n",
    "print(\"False Negatives: \", fn.result().numpy())\n",
    "print(\"False Positives: \", fp.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "confusion_matrix = [\n",
    "    [tn.result().numpy(), fp.result().numpy()],\n",
    "    [fn.result().numpy(), tp.result().numpy()]\n",
    "]\n",
    "\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
