{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:rgb(50, 120, 229);\"> Modelos preentrenados en Keras </font>\n",
    "\n",
    "Muchos modelos de CNN bien conocidos han sido **preentrenados** en grandes conjuntos de datos de referencia como **ImageNet**. \n",
    "\n",
    "La comunidad de Aprendizaje Profundo se ha beneficiado enormemente de estos modelos de código abierto. \n",
    "\n",
    "Además, los modelos preentrenados son un factor importante para los avances rápidos en la investigación de Visión por Computadora. Otros investigadores y profesionales pueden usar estos modelos de última generación en lugar de reinventar todo desde cero.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/VGG-16_pretrained.webp\" width=\"800px\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> ¿Cómo puedo usar un modelo preentrenado en Keras? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usarlos directamente para la clasificación de imágenes o podemos usarlos como punto de partida para un entrenamiento adicional para ajustarlos a nuestro propio conjunto de datos personalizado. Muchos de estos modelos de Última Generación ya están disponibles a través de [Keras Applications](https://keras.io/api/applications/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer la imagen de ejemplo y convertirla a RGB\n",
    "image = Image.open('./data/panda.png')\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los modelos preentrenados en Keras se pueden importar de la siguiente manera:\n",
    "\n",
    "```python\n",
    "from keras.applications import VGG16\n",
    "\n",
    "model = VGG16(\n",
    "    weights='imagenet',  \n",
    "    include_top=True,  \n",
    "    input_shape=(224, 224, 3)  \n",
    ")\n",
    "```\n",
    "\n",
    "**Parámetros:**\n",
    "\n",
    "- **weights**: especifica qué pesos cargar. Los valores posibles son `imagenet` (cargará los pesos preentrenados en ImageNet) o la ruta al archivo de pesos.\n",
    "- **include_top**: especifica si incluir o no la parte superior de la red (es decir, la capa de clasificación). Por defecto, esto excluye la capa de clasificación.\n",
    "- **input_shape**: la forma de la imagen que se utilizará con el modelo. Debe tener exactamente 3 canales de color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "model = VGG16(\n",
    "    weights='imagenet', \n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir la imagen a rgb y redimensionarla\n",
    "image = image.convert('RGB')\n",
    "image = image.resize((224, 224))\n",
    "\n",
    "#Convertir la imagen a un array de numpy\n",
    "image = np.array(image)\n",
    "\n",
    "\n",
    "#Convertir a tensor\n",
    "image = np.reshape(image, (1, 224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predecir la clase de la imagen\n",
    "prediction = model.predict(image)\n",
    "predicted_class = np.argmax(prediction[0])\n",
    "print(f'Clase predicha: {predicted_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "\n",
    "with open('./data/imagenet_classes.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        classes.append(line.strip())\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Clase predicha: {classes[predicted_class]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
