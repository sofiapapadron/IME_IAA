{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:rgb(50, 120, 229);\"> Probar un modelo de clasificación en tiempo real </font>\n",
    "\n",
    "En este cuadermo, vamos a probar un modelo de clasificación en tiempo real.\n",
    "\n",
    "Para ello, vamos a utilizar un modelo previamente entrenado y guardado en un archivo `.keras` o `.h5`.\n",
    "\n",
    "Nos apoyaremos en la librería `keras` para cargar el modelo y hacer predicciones en tiempo real y de la librería `opencv` para capturar el video de una cámara web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Fresh apple',\n",
    "               'Fresh banana',\n",
    "               'Fresh orange',\n",
    "               'Rotten apple',\n",
    "               'Rotten banana',\n",
    "               'Rotten orange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(original_image, model):\n",
    "    #Copiamos la imagen para no modificar la original\n",
    "    image = original_image.copy()\n",
    "    #Reescalamos la imagen al tamaño que espera el modelo (224x224)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "\n",
    "    #Convertimos la imagen a un tensor\n",
    "    image  = image.reshape(1, 224, 224, 3)\n",
    "\n",
    "    # Si el modelo incluye una capa de normalización, no es necesario normalizar la imagen\n",
    "    #image = image / 255.0\n",
    "    prediction = model.predict(image, verbose=0)\n",
    "\n",
    "    #Obtenemos el índice de la clase con mayor probabilidad\n",
    "    class_index = np.argmax(prediction)\n",
    "    class_name = class_names[class_index]\n",
    "\n",
    "    return class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Cargamos el modelo de red neuronal que hemos entrenado previamente\n",
    "model = load_model('./fruits.keras')\n",
    "\n",
    "# Creamos un objeto VideoCapture para capturar la imagen de la cámara\n",
    "# El parámetro 0 indica que se usará la cámara por defecto\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: No se puede abrir la cámara.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Capturamos un frame de la cámara\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Si no se ha podido capturar el frame, salimos del bucle\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Comprobamos si se ha pulsado una tecla\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    # Si se ha pulsado la tecla 'q', salimos del bucle\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "    label = predict_image(frame, model)\n",
    "\n",
    "    # Mostramos el texto con el nombre de la clase predicha\n",
    "    cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
