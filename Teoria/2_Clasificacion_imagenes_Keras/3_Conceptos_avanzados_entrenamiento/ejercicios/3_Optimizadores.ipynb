{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:rgb(50,120,229)\"> Optimizadores en Keras </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora en el curso, hemos utilizado varios optimizadores para entrenar modelos y revisado la teoría de cuatro tipos diferentes (SGD, SGD + Momentum, RMSProp y Adam). `tf.keras.optimizers` es un módulo de TensorFlow donde se implementan varios algoritmos de optimización.\n",
    "\n",
    "Puedes encontrar la documentación oficial [aquí](https://keras.io/api/optimizers/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este cuaderno, compararemos cuatro optimizadores diferentes utilizando el modelo LeNet5 y el conjunto de datos Fashion MNIST. \n",
    "\n",
    "Entrenaremos el modelo cuatro veces usando un optimizador diferente en cada caso, utilizando la tasa de aprendizaje predeterminada para cada optimizador y trazaremos la **pérdida** de entrenamiento para tener una mejor idea de las propiedades de convergencia de cada optimizador.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_loss(losses, title):\n",
    "    plt.plot(losses)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 28\n",
    "WIDTH = 28\n",
    "CHANNELS = 1\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 101\n",
    "LEARNING_RATE = 0.001\n",
    "ROOT_CHECKPOINT_DIR = \"optimizer_saved_models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:rgb(50,120,229)\"> 1. Cargar el conjunto de datos Fashion MNIST </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesaremos los datos para convertirlos en tensores y aplicamos one-hot encoding a las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "def preprocess_data(X_train, y_train, X_test, y_test):\n",
    "    X_train = X_train.reshape(-1, HEIGHT, WIDTH, CHANNELS)\n",
    "    X_test = X_test.reshape(-1, HEIGHT, WIDTH, CHANNELS)\n",
    "\n",
    "    y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "    y_test = to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = preprocess_data(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 2. Visualizar algunas imágenes </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    image = X_train[i]\n",
    "    label = class_names[y_train[i].argmax()]\n",
    "\n",
    "    plt.imshow(image.squeeze(), cmap='gray')\n",
    "    plt.title(label)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 3. Definir el modelo LeNet5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Resizing, Rescaling\n",
    "\n",
    "def build_model():\n",
    "    input_layer = Input(shape=(HEIGHT, WIDTH, CHANNELS))\n",
    "    resizig = Resizing(32, 32)(input_layer)\n",
    "    rescaling = Rescaling(1./255)(resizig)\n",
    "\n",
    "    conv1 = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(rescaling)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    flatten = Flatten()(pool2)\n",
    "\n",
    "    hidden1 = Dense(128, activation='relu')(flatten)\n",
    "    output_layer = Dense(NUM_CLASSES, activation='softmax')(hidden1)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 4. Definir el entrenamiento </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora solo habiamos creado un optimizador pasando como argumento el nombre del optimizador al método `compile`.\n",
    "\n",
    "Tambien podemos crear un objeto de optimizador y pasarlo al método `compile`. \n",
    "\n",
    "```python\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "def build_optimizer(optimizer_name, learning_rate):\n",
    "    if optimizer_name == 'adam':\n",
    "        return Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        return SGD(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'rmsprop':\n",
    "        return RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'momentum':\n",
    "        return SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError('Unknown optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def train_model(model, train_data, validation_data, optimizer_name):\n",
    "    optimizer = build_optimizer(optimizer_name, LEARNING_RATE)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=1)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_data[0], train_data[1],\n",
    "        validation_data=validation_data,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 5. Entrenar el modelo </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,229)\"> 5.1. Entrenar con SGD </font>\n",
    "\n",
    "Regla de actualización del descenso de gradiente:\n",
    "\n",
    "$$\n",
    "W_t = W_{t-1} -\\alpha g_{t-1}\n",
    "$$\n",
    "\n",
    "donde,\n",
    "\n",
    "$$\n",
    "W = \\begin{bmatrix}\n",
    "           w_{1} \\\\\n",
    "           w_{2} \\\\\n",
    "           \\vdots \\\\\n",
    "           w_{n}\n",
    "         \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "g = \\begin{bmatrix}\n",
    "           \\frac{\\partial L}{\\partial w_1} \\\\\n",
    "           \\frac{\\partial L}{\\partial w_2}  \\\\\n",
    "           \\vdots \\\\\n",
    "           \\frac{\\partial L}{\\partial w_n} \n",
    "         \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la actualización del descenso de gradiente estocástico, usamos el siguiente método en TensorFlow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.01, momentum=0.0, nesterov=False, name='SGD', **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "**Parámetros:**\n",
    "\n",
    "\n",
    "- `learning_rate` – Un Tensor, valor de punto flotante, o un horario que sea `tf.keras.optimizers.schedules.LearningRateSchedule`, o un callable que no toma argumentos y devuelve el valor real a usar. La tasa de aprendizaje. Por defecto es 0.01.\n",
    "\n",
    "- `momentum` – hiperparámetro flotante >= 0 que acelera el descenso de gradiente en la dirección relevante y amortigua las oscilaciones. Por defecto es 0, es decir, descenso de gradiente simple.\n",
    "\n",
    "- `nesterov` – booleano. Si se aplica el momentum de Nesterov. Por defecto es `False`.\n",
    "\n",
    "- `name` – Prefijo de nombre opcional para las operaciones creadas al aplicar gradientes. Por defecto es \"SGD\".\n",
    "\n",
    "- `**kwargs` – Argumentos clave. Permitido ser uno de \"clipnorm\" o \"clipvalue\". \"clipnorm\" (float) recorta los gradientes por norma; \"clipvalue\" (float) recorta los gradientes por valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = build_model()\n",
    "\n",
    "train_data = (X_train, y_train)\n",
    "validation_data = (X_test, y_test)\n",
    "\n",
    "sgd_history = train_model(lenet, train_data, validation_data, 'sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(sgd_history.history['loss'], 'SGD Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,229)\"> 5.2. Entrenar con SGD + Momentum </font>\n",
    "\n",
    "Regla de actualización del descenso de gradiente con momento:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "v_t &= \\beta v_{t-1} + (1 - \\beta) g_{t-1} \\\\\n",
    "\\\\\n",
    "W_t &= W_{t-1} - \\alpha v_t \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "En TensorFlow, usamos `tf.keras.optimizers.SGD` con un valor de momentum distinto de cero.\n",
    "\n",
    "En el siguiente entrenamiento, utilizaremos $\\beta = 0.9$. Aquí, $\\beta$ es el momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = build_model()\n",
    "momentum_history = train_model(lenet, train_data, validation_data, 'momentum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(momentum_history.history['loss'], 'Momentum Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,229)\"> 5.3. Entrenar con RMSProp </font>\n",
    "\n",
    "Regla de actualización de RMSProp:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "s_t &= \\beta s_{t-1} + (1 - \\beta) g_{t-1}^2 \\\\\n",
    "\\\\\n",
    "W_t &= W_{t-1} - \\alpha \\frac {g_{t-1}}{\\sqrt{s_t} + \\epsilon} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Para la actualización de pesos con RMSProp, usamos el siguiente método en TensorFlow:\n",
    "\n",
    "\n",
    "```python\n",
    "tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
    "    name='RMSprop', **kwargs\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parámetros:**\n",
    "\n",
    "- `learning_rate` – Un Tensor, valor de punto flotante, o un horario que sea `tf.keras.optimizers.schedules.LearningRateSchedule`, o un callable que no toma argumentos y devuelve el valor real a usar. La tasa de aprendizaje. Por defecto es 0.001.\n",
    "\n",
    "- `rho` – Factor de descuento para el historial/próximo gradiente. Por defecto es 0.9.\n",
    "\n",
    "- `momentum` – Un escalar o un Tensor escalar. Por defecto es 0.0.\n",
    "\n",
    "- `epsilon` – Una pequeña constante para la estabilidad numérica. Este epsilon es \"epsilon hat\" en el documento de Kingma y Ba (en la fórmula justo antes de la Sección 2.1), no el epsilon en el Algoritmo 1 del documento. Por defecto es 1e-7.\n",
    "\n",
    "- `centered` – Booleano. Si es `True`, los gradientes se normalizan por la varianza estimada del gradiente; si es False, por el segundo momento no centrado. Establecer esto en True puede ayudar con el entrenamiento, pero es ligeramente más costoso en términos de computación y memoria. Por defecto es `False`.\n",
    "\n",
    "- `name` – Prefijo de nombre opcional para las operaciones creadas al aplicar gradientes. Por defecto es \"`RMSprop`\".\n",
    "\n",
    "- `**kwargs` – Argumentos clave. Permitido ser uno de \"`clipnorm`\" o \"`clipvalue`\". \"`clipnorm`\" (float) recorta los gradientes por norma; \"`clipvalue`\" (float) recorta los gradientes por valor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = build_model()\n",
    "rmsprop_history = train_model(lenet, train_data, validation_data, 'rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(rmsprop_history.history['loss'], 'RMSprop Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,229)\"> 5.4. Entrenar con Adam </font>\n",
    "\n",
    "Regla de actualización de Adam:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "v_t &= \\beta_1 v_{t-1} + (1 - \\beta_1) g_{t-1} \\\\\n",
    "\\\\\n",
    "s_t &= \\beta_2 s_{t-1} + (1 - \\beta_2) g_{t-1}^2 \\\\\n",
    "\\\\\n",
    "W_t &= W_{t-1} - \\alpha \\frac {v_{t}}{\\sqrt{s_t} + \\epsilon} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Para la actualización de pesos con Adam, usamos el siguiente método en TensorFlow:\n",
    "\n",
    "```python\n",
    "tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam', **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "- `learning_rate` – Un Tensor, valor de punto flotante, o un horario que es `tf.keras.optimizers.schedules.LearningRateSchedule`, o un callable que no toma argumentos y devuelve el valor real a usar. La tasa de aprendizaje. Por defecto es 0.001.\n",
    "\n",
    "- `beta_1` – Un valor flotante o un tensor flotante constante, o un callable que no toma argumentos y devuelve el valor real a usar. La tasa de decaimiento exponencial para las estimaciones del primer momento. Por defecto es 0.9.\n",
    "\n",
    "- `beta_2` – Un valor flotante o un tensor flotante constante, o un callable que no toma argumentos y devuelve el valor real a usar. La tasa de decaimiento exponencial para las estimaciones del segundo momento. Por defecto es 0.999.\n",
    "\n",
    "- `epsilon` – Una pequeña constante para la estabilidad numérica. Este epsilon es \"epsilon hat\" en el documento de Kingma y Ba (en la fórmula justo antes de la Sección 2.1), no el epsilon en el Algoritmo 1 del documento. Por defecto es 1e-7.\n",
    "\n",
    "- `amsgrad` – Booleano. Si se aplica la variante AMSGrad de este algoritmo del documento \"Sobre la convergencia de Adam y más allá\". Por defecto es `False`.\n",
    "\n",
    "- `name` - Nombre opcional para las operaciones creadas al aplicar gradientes. Por defecto es \"Adam\".\n",
    "\n",
    "- `**kwargs` – Argumentos clave. Permitido ser uno de \"`clipnorm`\" o \"`clipvalue`\". \"`clipnorm`\" (float) recorta los gradientes por norma; \"`clipvalue`\" (float) recorta los gradientes por valor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = build_model()\n",
    "adam_history = train_model(lenet, train_data, validation_data, 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(adam_history.history['loss'], 'Adam Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 6. Conclusiones </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,229)\"> 6.1. Gráfica de pérdida en el conjunto de entrenamiento </font>\n",
    "\n",
    "Al evaluar optimizadores, es importante estudiar la **pérdida** de entrenamiento para entender el comportamiento de convergencia en los datos de entrenamiento. \n",
    "\n",
    "Recuerda que para un modelo y conjunto de datos dados, el trabajo del optimizador es rendir bien en los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"./images/loss.png\" width=1500>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se muestra en el gráfico anterior, SGD (rojo) tiene la pérdida más alta de los cuatro optimizadores, mientras que Adam (verde) eventualmente alcanza la pérdida más baja. Además, observa que SGD+Momentum (azul) sigue una tendencia muy similar a Adam, aunque no tan baja. Inicialmente, RMSProp (negro) converge más rápido en las primeras 10-15 épocas, pero si observas cuidadosamente, comienza a divergir después de aproximadamente 40-50 épocas, lo cual no es deseable. \n",
    "\n",
    "Entonces, para este modelo y conjunto de datos, Adam claramente tiene el mejor rendimiento. Pero hay un par de advertencias. Primero, recuerda que en cada caso, utilizamos la tasa de aprendizaje predeterminada para cada optimizador, lo cual es algo bueno para hacer inicialmente.\n",
    "\n",
    "Una vez que tengas una línea de base, puedes ajustar las tasas de aprendizaje para cada optimizador para ver cómo afecta eso a los resultados.\n",
    "\n",
    "Aunque Adam generalmente funciona muy bien en una amplia gama de condiciones, no necesariamente es la mejor opción para todos los problemas, y al menos deberías experimentar inicialmente para ver qué optimizador parece ser el mejor. Una vez que seleccionas un optimizador, a menudo es necesario experimentar más para ajustar el entrenamiento de tu modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,229)\"> 6.1. Gráfica de pérdida en el conjunto de validación </font>\n",
    "\n",
    "Aunque a menudo estudiamos la pérdida de validación al entrenar modelos, este no debería ser el criterio por el cual se selecciona un optimizador, ya que el trabajo del optimizador es lograr una convergencia rápida y estable en los datos de entrenamiento. Sin embargo, vale la pena estudiar la pérdida de validación en este caso para hacer algunos puntos.\n",
    "\n",
    "<center>\n",
    "    <img src=\"./images/valid.png\" width=1500>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gráfico anterior, primero notamos que la pérdida para tres optimizadores comienza a divergir después de aproximadamente 10-15 épocas. El optimizador SGD tarda más en converger, pero se aplana y realmente no parece divergir. Entonces, puede ser tentador concluir que SGD podría ser una buena elección. Pero nuevamente, debemos recordar que si bien la pérdida de validación es importante para ajustar finamente el modelo y los hiperparámetros para un optimizador dado, **este no debería ser el criterio por el cual se selecciona un optimizador.**\n",
    "\n",
    "Pero si comparas estas curvas cuidadosamente, verás que Adam, SGD+Momentum y RMSProp alcanzan aproximadamente el mismo mínimo (pérdida de validación) en algún lugar entre 8 y 15 épocas, todos tienen una pérdida más baja que el optimizador SGD (rojo), que tarda mucho más en alcanzar su valor mínimo. Entonces, aunque no queremos usar la pérdida de validación como criterio para seleccionar el **tipo** de optimizador a utilizar, el hecho de que los otros tres optimizadores logren una pérdida más baja que SGD en solo unas pocas épocas es una buena indicación de que tienen mejores propiedades de convergencia que SGD.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
