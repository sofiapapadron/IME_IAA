{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:rgb(50, 120, 229);\"> Como prevenir el sobre ajuste </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El sobreajuste es una condición en la que el modelo funciona muy bien en los datos de entrenamiento y no tan bien en los datos de prueba. \n",
    "\n",
    "*El sobreajuste siempre me recuerda a algunos niños en la escuela que lo hacen muy bien en los exámenes cuando las preguntas son exactamente las mismas que se cubrieron en clase. Cambia un poco la pregunta y les va horriblemente mal. En cierto sentido, han memorizado las respuestas pero no han aprendido el concepto subyacente.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no tienes cuidado, tu red neuronal hará lo mismo. Memorizará las respuestas a los datos en el conjunto de entrenamiento y, por lo tanto, no aprenderá realmente a generalizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> **¿Cómo  se ve el sobreajuste?** </font>\n",
    "\n",
    "En este gráfico, la curva azul muestra la pérdida de entrenamiento y la curva roja muestra la pérdida de validación. Puedes ver que después de cierto número de épocas, el modelo comienza a sobreajustarse.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/sobreajuste.png\" width=\"500px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> ¿Por qué ocurre el sobreajuste? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tienes un conjunto de entrenamiento pequeño en comparación con la capacidad del modelo, el sobreajuste es inevitable.\n",
    "\n",
    "<font style=\"color:rgb(50, 120, 229);\"> **¿Qué puedes hacer?** </font>\n",
    "\n",
    "La primera forma de abordar el problema es obtener más datos. Puedes aumentar tus datos, lo que simplemente significa crear nuevos datos de entrenamiento modificando los datos existentes. Si es posible, puedes ir y recopilar más datos, o a veces puede ser posible sintetizar datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La segunda solución es **Early Stopping**. Simplemente significa que eliges los parámetros del modelo justo antes de que comience el sobreajuste en el proceso de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> Regularización </font>\n",
    "\n",
    "Ahora, veamos algunos cambios algorítmicos y de arquitectura que necesitamos para corregir el sobreajuste. Esta intervención se llama **regularización**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> **Ejemplo para entender la regularización** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digamos que tenemos y, que es una función de la variable x. \n",
    "\n",
    "Tenemos algunos puntos de datos muestreados de esta función. Nuestro objetivo es encontrar una curva que pase por todos los puntos, y estos puntos representan nuestro conjunto de entrenamiento.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/train_points.png\" width=\"400px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, veamos la primera solución. Esta parece bastante buena, pero la solución 2 también es técnicamente correcta porque esta segunda curva también pasa por todos los puntos.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/solutions.png\" width=\"800px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afortunadamente, en el aprendizaje automático podemos saber qué solución es mejor al verificar el error cometido por el modelo en el conjunto de validación. Los puntos morados mostrados aquí son del conjunto de validación y puedes ver que están muy lejos de la solución 2. \n",
    "\n",
    "Aunque los errores de entrenamiento para ambas curvas son iguales, el error de validación nos dice que la solución 1 es mejor que la solución 2. La pregunta ahora es, ¿cómo solucionamos este problema de sobreajuste?\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/overfitting.png\" width=\"800px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> **Eligue un modelo más simple** </font>\n",
    "\n",
    "Podemos decir que vamos a ajustar los datos con un polinomio de grado 2. \n",
    "\n",
    "Así que este es un modelo simple y simplemente es una parábola, y la curva no va a oscilar mucho porque la hemos restringido diciendo que solo vamos a usar un polinomio de grado 2. Podemos encontrar la función de pérdida y minimizarla. \n",
    "\n",
    "El problema con este enfoque es que hemos tomado una decisión difícil sobre la complejidad del problema. \n",
    "\n",
    "El mismo polinomio no funcionará con un problema ligeramente diferente donde los datos sean un poco más complejos.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/simple_model.png\" width=\"800px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> **Regularización L2** </font>\n",
    "\n",
    "Podemos elegir un modelo mucho más complejo pero evitar que sea demasiado flexible. Esta es la ventaja de que el mismo modelo pueda resolver tareas simples y complejas. Tiene la capacidad porque es complejo y tiene la disciplina que imponemos usando la regularización.\n",
    "\n",
    "Podemos reescribir y como una función de las x de forma compacta. Entonces, la pérdida se da por esta expresión y, como antes, queremos minimizar esta pérdida. Si intentamos minimizar esta pérdida, el problema está impuesto y hay varias soluciones.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/complex_model.png\" width=\"800px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos agregar este término llamado término de regularización. \n",
    "\n",
    "Hay dos partes en este término. \n",
    "\n",
    "- La primera parte es lambda, que es un hiperparámetro y controla la cantidad de regularización que queremos. \n",
    "- La segunda parte es la norma del vector de pesos, por lo que es esencialmente $w_1$ al cuadrado más $w_2$ al cuadrado hasta $w_m$ al cuadrado, donde m es el número de pesos\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/regularization.png\" width=\"800px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, no solo estamos tratando de minimizar la pérdida original, sino que también estamos tratando de mantener los pesos pequeños. Esto limita el modelo porque la curva no tiene suficiente flexibilidad para tomar cualquier forma.\n",
    "\n",
    "Pesos más pequeños significan modelos más simples, y una vez que agregamos este término de regularización y minimizamos la función de pérdida, es probable que obtengamos una curva mucho más simple como esta.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/regularized_model.png\" width=\"800px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, el término de regularización era básicamente el cuadrado de la norma L2 del peso, por eso esta regularización se llama **regularización L2 o regularización ridge**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> **Regularización L1** </font>\n",
    "\n",
    "También puedes usar la regularización L1, que a veces se llama regularización Lasso. \n",
    "\n",
    "La diferencia entre las dos es que L1 produce pesos que son cero mucho más a menudo que L2. \n",
    "\n",
    "En otras palabras, el vector de pesos cuando usamos la regularización L1 suele ser disperso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> Dropout </font>\n",
    "\n",
    "A continuación, veamos el dropout, donde la arquitectura de la red se modifica durante el entrenamiento para lograr el mismo objetivo.\n",
    "\n",
    "En el dropout, comenzamos con una red neuronal con múltiples capas. Se puede aplicar a cualquier tipo de red neuronal, ya sea perceptrones multicapa o CNN.\n",
    "\n",
    "\n",
    "<font style=\"color:rgb(50, 120, 229);\"> **¿Cómo funciona el dropout?** </font>\n",
    "\n",
    "Al inicio de cada iteración con un mini lote, seleccionamos aleatoriamente neuronas con una probabilidad $p$. \n",
    "\n",
    "Si la neurona no es seleccionada, se apaga, es decir, todas las entradas y salidas de la neurona se eliminan de la red.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/droput_before.png\" width=\"500px\">\n",
    "</center>\n",
    "\n",
    "Si la probabilidad $p$ es igual a 0.5, la mitad de las neuronas se eliminan de la red.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/droput.png \" width=\"500px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego realizamos un pase hacia adelante a través de esta red adelgazada y calculamos la pérdida. \n",
    "\n",
    "Luego calculamos el gradiente usando retropropagación y actualizamos los pesos de las neuronas, por lo que este es el ciclo de entrenamiento estándar. \n",
    "\n",
    "Pero antes de seleccionar el próximo mini lote, **actualizamos la red y apagamos un conjunto diferente de neuronas**, por lo que esencialmente **estamos entrenando una versión diferente de la red cada vez.**\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/droput_2.png\" width=\"500px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> **¿Por qué funciona el dropout?** </font>\n",
    "\n",
    "<font style=\"color:rgb(50, 120, 229);\"> **Previene la coadaptación** </font>\n",
    "\n",
    "Las redes pequeñas no son tan complejas como la red original, son aproximadamente la mitad del tamaño, si $p$ es igual a 0.5 y, por lo tanto, es menos probable que sobreajusten. \n",
    "\n",
    "Además, como cada neurona está recibiendo entradas de una colección aleatoria de neuronas en cada iteración, no depende en gran medida de las neuronas en la capa anterior para aprender su peso. \n",
    "\n",
    "En otras palabras, **las neuronas no están coadaptando con otras neuronas** y, por lo tanto, es menos probable que sobreajusten.\n",
    "\n",
    "<font style=\"color:rgb(50, 120, 229);\"> **Aproximación de conjuntos** </font>\n",
    "\n",
    "Con dropout, una red neuronal también aproxima un conjunto, lo que mejora la precisión. Veamos qué significa eso.\n",
    "\n",
    "Digamos que tienes cuatro redes neuronales diferentes entrenadas para resolver el mismo problema de clasificación. Cada una proporciona una precisión del 90%. \n",
    "\n",
    "Si promedias los resultados de todas ellas, típicamente obtendrás una precisión ligeramente mejor. Esto se debe a que cada red comete un tipo diferente de error que se promedia cuando las combinamos.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/avg_accuracy.png\" width=\"600px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar muchas redes neuronales para crear el conjunto lleva tiempo, pero con dropout estamos aproximando la idea de un conjunto porque las redes neuronales reducidas pueden considerarse como una colección de redes neuronales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> **¿Cómo hacer predicciones con dropout?** </font>\n",
    "\n",
    "Es posible que te estés preguntando cómo usar esta red durante la prueba o inferencia. ¿Deberías usar toda la red o deberías usar dropout incluso durante la inferencia? La respuesta es que uses toda la red; sin embargo, multiplicas los pesos salientes por la probabilidad de dropout.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/dropout_inferences.png\" width=\"800px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\"> **Consideraciones finales** </font>\n",
    "\n",
    "- Primero que todo, dropout no es completamente gratuito. Entrenar la red lleva de dos a tres veces más tiempo. \n",
    "- En segundo lugar, durante el entrenamiento, debes aumentar la tasa de aprendizaje en 10x a 200x en comparación con lo que habrías usado para la red original. \n",
    "- También necesitas usar un momento alto en lugar del típico 0.9; usamos de 0.95 a 0.99. \n",
    "- Dropout funciona muy bien cuando también usamos la regularización de la norma máxima con la función de pérdida. Por lo tanto, dropout más la regularización de la norma máxima produce resultados superiores en comparación con dropout solo. \n",
    "- Finalmente, la probabilidad de dropout p se puede establecer entre 0.5 y 0.8 para las capas ocultas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> Batch Normalization </font>\n",
    "\n",
    "La normalización por lotes (batch norm) es similar a dropout en el sentido de que ajusta cada unidad oculta por un valor aleatorio en cada paso del entrenamiento. \n",
    "\n",
    "Sin embargo, en el caso de la normalización por lotes, este valor aleatorio es la desviación estándar de todas las unidades ocultas en el mini lote. \n",
    "\n",
    "Dado que diferentes ejemplos se eligen aleatoriamente para su inclusión en el mini lote en cada paso, la desviación estándar fluctúa aleatoriamente.\n",
    "\n",
    "Además, la normalización por lotes también resta un valor aleatorio, que es la media del mini lote, de cada unidad oculta en cada paso. Ambas fuentes de ruido significan que cada capa tiene que aprender a ser robusta a una gran cantidad de variación en su entrada, al igual que dropout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**En general, cuando dificultamos que la red aprenda de manera sistemática, tiende a aprender de manera más robusta y utiliza la capacidad excesiva de la red para la robustez en lugar de intentar sobreajustar los datos de entrenamiento.**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
