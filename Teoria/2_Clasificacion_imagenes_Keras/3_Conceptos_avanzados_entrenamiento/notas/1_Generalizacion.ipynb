{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:rgb(50, 120, 229);\"> Compromiso entre sesgo y varianza</font>\n",
    "\n",
    "En este cuaderno desarrollaremos un sentido intuitivo para un concepto importante en el aprendizaje automático llamado el **compromiso entre sesgo y varianza**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\">**¿Cómo aprendemos?**</font>\n",
    "\n",
    "Antes de sumergirnos en el tema, permíteme salirme un poco del tema y hablar sobre el aprendizaje humano:\n",
    "\n",
    "Practicar solo no te hace mejor en una habilidad. Todos conocemos personas que practican muy duro pero parecen no lograr mucho. La razón es que no dirigen su esfuerzo de manera adecuada. \n",
    "\n",
    "Para un novato que está aprendiendo a tocar el piano, es tentador tocar la melodía que ha dominado una y otra vez porque se siente cómodo y proporciona mucha alegría y sensación de logro. Sin embargo, **este comportamiento no la ayuda a mejorar su habilidad**.\n",
    "\n",
    "La forma correcta de practicar es identificar tus áreas más débiles y dirigir un esfuerzo masivo en mejorar esas áreas sin preocuparte demasiado por las áreas en las que ya eres bueno.\n",
    "\n",
    "Esta forma de práctica no es placentera, es lenta, frustrante y muy difícil. Pero la práctica deliberada es extremadamente efectiva para mejorar el rendimiento. **El mismo principio se aplica en el aprendizaje automático.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\">**¿Cómo mejorar un modelo de aprendizaje automático?**</font>\n",
    "\n",
    "- Se obtienen enormes ganancias en rendimiento cuando diriges todo tu esfuerzo hacia comprender tus errores y minimizarlos.\n",
    "\n",
    "- Utiliza flujos de trabajo conocidos; de lo contrario, pasarás mucho tiempo probando diferentes cosas sin reducir sistemáticamente tus errores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50, 120, 229);\"> Problema de Ejermplo</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegiremos un problema sencillo con un pequeño número de parámetros. Nuestros datos consistirán en puntos 2D con coordenadas x e y, como se muestra en el gráfico. \n",
    "\n",
    "<center>\n",
    "<img src=\"./images/plot_dummy.png\" width=400>\n",
    "</center>\n",
    "\n",
    "Aquí, x es un parámetro variable y y es la función de este parámetro. Por ejemplo, x podría ser el tamaño de una casa y y su costo. \n",
    "\n",
    "**Nuestro objetivo es construir un modelo que pueda predecir y para nuevos valores no vistos de x.** \n",
    "\n",
    "### <font style=\"color:rgb(50, 120, 229);\"> **Generalización** </font>   \n",
    "\n",
    "En el aprendizaje automático, la capacidad del modelo para funcionar bien con datos no vistos se llama generalización.\n",
    "\n",
    "Nuestro objetivo es crear un modelo que generalice bien. \n",
    "\n",
    "### <font style=\"color:rgb(50, 120, 229);\"> **¿Cómo obtenemos un modelo que generalice bien?** </font>\n",
    "\n",
    "<font style=\"color:rgb(50, 120, 229);\">**1. Mezclar los datos**</font>\n",
    "\n",
    "Como siempre, debemos primero mezclar aleatoriamente los datos. \n",
    "\n",
    "Este es un paso importante porque muchas veces los datos que recibimos están ordenados de alguna manera, por ejemplo, podrían estar ordenados por fecha. \n",
    "\n",
    "Este tipo de órdenes inevitablemente conducirán a sesgos divertidos en nuestro modelo. \n",
    "\n",
    "**La mezcla de datos hace que sea más fácil para el modelo generalizar para datos no vistos**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\">**2. Dividir los datos**</font>\n",
    "\n",
    "A continuación, dividimos los datos en conjuntos de entrenamiento y prueba. \n",
    "\n",
    "Utilizaremos el 60% de los datos para el entrenamiento y el 40% para la prueba. \n",
    "\n",
    "Como su nombre sugiere, solo entrenaremos en el conjunto de entrenamiento y probaremos en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> **Modelo de ejemplo** </font>\n",
    "\n",
    "Digamos que decidimos ajustar los datos usando un polinomio de grado n. Ahora necesitamos entrenar un modelo para encontrar buenos valores para los parámetros $a_0$ hasta $a_n$ y probarlo en el conjunto de validación. \n",
    "\n",
    "Pero, ¿qué valor de n deberíamos elegir? Comenzaremos primero con n igual a 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ambos gráficos que vemos aquí, los puntos rojos son puntos de datos 2D en el conjunto de entrenamiento. \n",
    "\n",
    "<font style=\"color:rgb(50, 120, 229);\">**Subajuste**</font>\n",
    "\n",
    "En el gráfico, ajustamos una línea con pendiente cero, aquí n es igual a cero. Naturalmente, la línea no puede pasar por todos los puntos y hay un error entre los datos, que son los puntos rojos, y el valor predicho, que es la línea azul.\n",
    "\n",
    "Podemos ver claramente que este es un mal ajuste. El error es de 1500. No hay forma de que una línea con pendiente cero se ajuste bien a estos datos porque el modelo de línea no tiene suficiente flexibilidad. En tales casos, decimos que el modelo está subajustando los datos.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/plot_underfit.png\" width=400>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\">**Mejor ajuste**</font>\n",
    "\n",
    "En el siguiente gráfico hay una línea con una pendiente. En este ejemplo, el error es aproximadamente 3.6. Podemos ver claramente que esta línea se ajusta mucho mejor a los datos que la línea sin pendiente. \n",
    "\n",
    "La pregunta es: ¿podemos hacerlo mejor? Podemos ver que una línea recta nunca ajustará completamente los datos, necesitamos una línea ondulada.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/plot_goodfit.png\" width=400>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50, 120, 229);\">**Sobreajuste**</font>\n",
    "\n",
    "Podemos usar un polinomio de grado 5 y obtener una línea ondulada que se ajuste mucho mejor a los datos. \n",
    "\n",
    "El error disminuye aproximadamente a 1.69, la forma en que el nuevo modelo polinómico se ajusta a los datos parece emocionante. \n",
    "\n",
    "<center>\n",
    "<img src=\"./images/plot_overfit.png\" width=400>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto significa que tal vez deberíamos usar un polinomio de grado aún mayor para obtener una curva mucho más ondulada y reducir el error a cero.\n",
    "\n",
    "Para decidir eso, veamos el rendimiento de los dos modelos en el conjunto de validación que hemos dejado fuera. Como recordarás, el conjunto de validación no se usó para entrenar el modelo. Estos gráficos muestran cómo se desempeñan los mismos dos modelos en el conjunto de validación no visto.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/model_comp.png\" width=800>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulta que la emoción de ver que el error disminuye en el conjunto de entrenamiento con el modelo polinómico fue de corta duración. \n",
    "\n",
    "Para el modelo lineal, el error en el conjunto de validación es muy cercano al error que habíamos visto en el conjunto de entrenamiento. En tales casos, decimos que el modelo ha generalizado bien para datos no vistos. \n",
    "\n",
    "Para el modelo polinómico, el error es astronómico, es de 929. El modelo que pensábamos que era excelente es, de hecho, bastante malo. Este problema, donde **el modelo funciona muy bien en los datos de entrenamiento pero funciona mal en los datos de validación, se llama sobreajuste**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> **Entendiendo el compromiso entre sesgo y varianza** </font>\n",
    "\n",
    "Como se mencionó anteriormente, el modelo lineal tiene un sesgo más alto. \n",
    "\n",
    "Por otro lado, el modelo polinómico sufre de un problema diferente. El modelo depende mucho de la elección de los datos de entrenamiento. Si cambiamos ligeramente los datos, la forma de la curva se verá muy diferente y el error variará ampliamente. Por lo tanto, se dice que el modelo tiene una alta varianza.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acabamos de obtener una muestra del compromiso entre sesgo y varianza. \n",
    "\n",
    "Para mantener el sesgo bajo, necesitamos un modelo complejo, por ejemplo, necesitamos un polinomio con un grado alto. Pero un modelo complejo tiende a sobreajustarse y aumentar la varianza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> **Entendiendo el Machine Learning** </font>\n",
    "\n",
    "El aprendizaje automático no es una búsqueda de la perfección. No queremos llevar el error a cero, pero se trata de buscar el mejor compromiso. \n",
    "\n",
    "En el aprendizaje automático, el error cometido por tu modelo es una suma de tres tipos de errores: el error debido al sesgo en nuestro modelo, el error debido a la varianza del modelo y, finalmente, el error que es irreducible.\n",
    "\n",
    "<font style=\"color:rgb(50, 120, 229);\">**Sesgo**</font>\n",
    "\n",
    "El sesgo describe cuán diferentes son las predicciones del modelo del valor real en los datos de entrenamiento. \n",
    "\n",
    "Si el sesgo es alto, resulta en un subajuste de los datos. \n",
    "\n",
    "Un sesgo alto puede significar que el modelo es demasiado simple y, por lo tanto, omite cosas importantes sobre la relación en nuestros datos, por lo que necesitamos un modelo más complejo para ajustar los datos que tenemos.\n",
    "\n",
    "<font style=\"color:rgb(50, 120, 229);\">**Varianza**</font>\n",
    "\n",
    "Por otro lado, la varianza típicamente significa que el modelo es demasiado complejo. Hay demasiados parámetros y se ajusta muy bien a los datos de entrenamiento. \n",
    "\n",
    "Una alta varianza significa que el modelo tiene una gran diferencia entre su precisión en el conjunto de entrenamiento y el conjunto de pruebas. Esto se debe a que un modelo así aprendió demasiado bien los datos de entrenamiento, incluso memorizó su ruido, y ahora es demasiado sensible a pequeños cambios en los datos.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/bias_variance.png\" width=400>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> **¿Cómo se ve el compromiso entre sesgo y varianza?** </font>\n",
    "\n",
    "La figura muestra gráficamente el efecto de la complejidad del modelo en el error debido al sesgo y la varianza. \n",
    "\n",
    "La región a la izquierda, donde tanto los errores de entrenamiento como de validación son altos, es la región de alto sesgo. Por otro lado, la región a la derecha, donde el error de validación es alto pero el error de entrenamiento es bajo, es la región de alta varianza.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/bias_variance_plot.png\" width=600>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos estar en el punto óptimo en el medio ahora.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50, 120, 229);\"> **¿Cómo encontrar el mejor modelo?** </font>\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/improve_model.png\" width=800>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
