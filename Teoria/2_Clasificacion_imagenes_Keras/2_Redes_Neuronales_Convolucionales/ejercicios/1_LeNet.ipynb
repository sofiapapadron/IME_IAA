{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:rgb(50,120,229)\"> Implementando LeNet-5 </font>\n",
    "\n",
    "En este cuaderno, construiremos un modelo de la arquitectura CNN LenNet-5 en Keras y lo utilizaremos para realizar clasificación en el conjunto de datos MNIST. \n",
    "\n",
    "LenNet-5 es un modelo CNN pequeño que se presentó por primera vez en 1998. Aunque esta red es muy pequeña, tiene un rendimiento mucho mejor que una red MLP estándar porque las CNN son mucho más efectivas en el procesamiento de datos de imágenes. \n",
    "\n",
    "<center>\n",
    "<img src=\"./images/LeNet-5_architecture.png\" width=800px>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "NUM_CLASSES = 10\n",
    "IMAGE_SIZE = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,229)\"> 1. Cargar el conjunto de datos MNIST </font>\n",
    "\n",
    "Primero, cargaremos el conjunto de datos MNIST.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/mnist.png\" width=800px>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 2 Visualizar algunas imágenes </font>\n",
    "\n",
    "Vamos a crear una función para visualizar algunas imágenes del conjunto de datos MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Importa la función to_categorical de keras.utils y convierte las etiquetas a one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 2. Modelar LenNet-5 </font>\n",
    "\n",
    "\n",
    "La arquitectura de LenNet-5 es:\n",
    "\n",
    "- **Capa de entrada**: La imagen de entrada es de tamaño `32x32x1`.\n",
    "- **Capa 1**: Convolucional con 6 filtros de tamaño `5x5` y función de activación `ReLU`.\n",
    "- **Capa 2**: MaxPooling con un filtro de tamaño `2x2`.\n",
    "- **Capa 3**: Convolucional con 16 filtros de tamaño `5x5` y función de activación `ReLU`.\n",
    "- **Capa 4**: MaxPooling con un filtro de tamaño `2x2`.\n",
    "- **Capa 5**: Aplanar la salida de la capa anterior.\n",
    "- **Capa 6**: Totalmente conectada con 120 neuronas y función de activación `ReLU`.\n",
    "- **Capa 7**: Totalmente conectada con 84 neuronas y función de activación `ReLU`.\n",
    "- **Capa de salida**: Totalmente conectada con 10 neuronas (número de clases en MNIST) y función de activación `Softmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Crea un modelo Secuencial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerda que las imágenes del MNIST tienen un tamaño de `28x28`. \n",
    "\n",
    "Definiremos una capa de entrada que cumpla con estas dimensiones y luego las reescalaremos a `32x32` para que coincidan con las dimensiones de entrada esperadas por la red LenNet-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Define una capa de entrada que reciba una imagen de 28x28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como mencionamos anteriormente, la red LenNet-5 espera imágenes de tamaño `32x32`. Por lo tanto, necesitamos reescalar las imágenes de entrada de `28x28` a `32x32`.\n",
    "\n",
    "Esto se puede lograr utilizando la capa `Resizing` de Keras. \n",
    "\n",
    "```python\n",
    "from keras.layers import Resizing\n",
    "\n",
    "model.add(\n",
    "    Resizing(height, width, interpolation=\"bilinear\", crop_to_aspect_ratio=False, pad_to_aspect_ratio=False, fill_mode=\"constant\", fill_value=0.0)\n",
    ")\n",
    "```\n",
    "\n",
    "**Parámetros:**\n",
    "\n",
    "- `height`: Altura de la imagen de salida.\n",
    "- `width`: Ancho de la imagen de salida.\n",
    "- `interpolation`: Método de interpolación utilizado para redimensionar la imagen. Puede ser uno de los siguientes valores: `nearest`, `bilinear`, `bicubic`, `lanczos3`, `lanczos5`.\n",
    "- `crop_to_aspect_ratio`: Si es `True`, la imagen se recortará para que tenga la misma relación de aspecto que la imagen de entrada.\n",
    "- `pad_to_aspect_ratio`: Si es `True`, la imagen se rellenará para que tenga la misma relación de aspecto que la imagen de entrada.\n",
    "- `fill_mode`: Cuando pad_to_aspect_ratio es `True`, este parámetro especifica el método de relleno. Solo `constant` es compatible.\n",
    "- `fill_value`: Valor de relleno cuando `fill_mode` es `constant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Agrega una capa de resizing con fill_mode='constant' y valor de relleno 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro paso importante es normalizar las imágenes. Cuando se trabaja con imágenes la normalización común es dividir por 255.0 para que los valores de píxeles estén en el rango `[0, 1]`.\n",
    "\n",
    "Este proceso se puede conseguir con la capa `Rescaling` de Keras.\n",
    "\n",
    "```python\n",
    "from keras.layers import Rescaling\n",
    "\n",
    "model.add(Rescaling(scale=1.0 / 255))\n",
    "```\n",
    "\n",
    "**Parámetros:**\n",
    "\n",
    "- `scale`: Factor de escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Añade una capa Rescaling al modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente capa es una capa convolucional con 6 filtros de tamaño `5x5` y función de activación `ReLU`. \n",
    "\n",
    "```python\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=6,\n",
    "        kernel_size=(5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding=\"valid\",\n",
    "        activation=\"relu\",\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "**Parámetros:**\n",
    "\n",
    "- `filters`: Número de filtros.\n",
    "- `kernel_size`: Tamaño del kernel.\n",
    "- `strides`: Desplazamiento del kernel.\n",
    "- `padding`: Método de relleno.\n",
    "- `activation`: Función de activación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Agrega la primera capa convolucional al modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de la capa convolucional, agregamos una capa de MaxPooling con un filtro de tamaño `2x2`.\n",
    "\n",
    "```python\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "```\n",
    "\n",
    "**Parámetros:**\n",
    "\n",
    "- `pool_size`: Tamaño del filtro.\n",
    "- `strides`: Desplazamiento del filtro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Agrega una capa de MaxPooling2D al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Agrega la segunda capa convolucional al modelo y la capa de MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despues de la última capa de agrupación, aplanamos la salida de la capa anterior. Esto se puede hacer con la capa `Flatten` de Keras.\n",
    "\n",
    "```python\n",
    "from keras.layers import Flatten\n",
    "\n",
    "model.add(Flatten())\n",
    "```\n",
    "\n",
    "**Aplanar la salida es necesario para conectar la salida de la capa convolucional a la capa totalmente conectada.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Agrega una capa de Flatten al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Agrega las capas densas al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Muestra un resumen del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 4. Entrenar LenNet-5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Compila el modelo utilizando el optimizador 'adam', la función de pérdida 'categorical_crossentropy' y la métrica 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Entrena el modelo con los datos de entrenamiento, utiliza un validation_split del 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Grafica la pérdida y la precisión del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 5. Evaluación del modelo </font>\n",
    "\n",
    "Finalmente, evaluaremos el modelo en el conjunto de datos de prueba y visualizaremos algunas predicciones. \n",
    "\n",
    "Esto nos dará una idea de cómo se desempeña nuestro modelo en datos que nunca ha visto antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Evalúa el modelo con los datos de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,229)\"> 5.1. Visualizar algunas predicciones </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Realiza algunas predicciones con los datos de test y muestra las imágenes y su predicción"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
