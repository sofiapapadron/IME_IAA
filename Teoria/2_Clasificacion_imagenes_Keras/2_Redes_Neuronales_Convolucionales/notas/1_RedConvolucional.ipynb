{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color: rgb(50,120,229)\"> Introducción a las Redes Neuronales Convolucionales </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos discutido en secciones anteriores, las redes neuronales consisten en una serie de neuronas artificiales conectadas. Las conexiones entre neuronas son dirigidas y la señal de una neurona a otra viaja solo en una dirección especificada.\n",
    "\n",
    "También discutimos que las neuronas están divididas en capas. Una red neuronal tiene una capa de entrada, unas pocas capas ocultas y una capa de salida.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/mlp.png\" width=600>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También sabemos que una red neuronal con una o más capas ocultas se llama perceptrón multicapa. \n",
    "\n",
    "El MLP sufre de un gran inconveniente, especialmente cuando se trabaja con datos de imágenes. Una sola imagen de color de 256 por 256, lo que significa que tiene tres canales, requiere una entrada de tamaño de 196,608. Crear un perceptrón multicapa con una entrada tan grande requiere decenas de millones de pesos porque las capas en un MLP están densamente conectadas.\n",
    "\n",
    "**Eso nos lleva a las redes neuronales convolucionales o CNNs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color: rgb(50,120,229)\"> ¿Qué son las Redes Neuronales Convolucionales? </font>\n",
    "\n",
    "Las CNNs, al igual que los MLPs, consisten en una pila de capas que reciben una imagen de entrada. \n",
    "\n",
    "Estas capas realizan una serie de operaciones matemáticas que suelen ser transformaciones lineales con activaciones no lineales, y predicen las probabilidades de clase o etiqueta en la salida.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/cnn.png\" width=800>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferencia de un MLP, las neuronas en una capa de CNN no están conectadas a todas las neuronas de la capa anterior. \n",
    "\n",
    "En cambio, las neuronas de una capa de CNN solo están conectadas a una pequeña región de la capa anterior, pero se aplican a toda la capa de entrada en una ventana deslizante.\n",
    "\n",
    "Otra diferencia es que generalmente las convoluciones se aplican a datos 2D, por lo que cada neurona ve un parche local algo significativo de una entrada.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/conv.png\" width=800>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color: rgb(50,120,229)\"> **¿De donde se inspiran las CNNs?** </font>\n",
    "\n",
    "Esta idea de patrones locales proviene de la biología. Es una aproximación de cómo funciona la corteza visual de los animales, incluidos los humanos. \n",
    "\n",
    "Se demostró en una serie de trabajos realizados por D. H. Hubel y T. N. Wiesel que la corteza visual contiene diferentes tipos de células. \n",
    "\n",
    "- Las células simples responden a la iluminación de pequeñas regiones de la retina que siguen patrones simples como manchas, bordes, etc., y aparentemente realizan una suma dentro de estas regiones. \n",
    "- También hay células complejas que no pueden ser invocadas por estos patrones locales; son invocadas por formas grandes como una línea larga de luz.\n",
    "-  Se sugirió que un grupo de células simples está conectado a una sola célula compleja que combina sus respuestas y envía una señal de excitación más allá si se encuentra alguna forma compleja.\n",
    "   \n",
    "<center>\n",
    "<img src=\"./images/biological.png\" width=800>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color: rgb(50,120,229)\"> ¿Cómo funcionan las CNNs? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color: rgb(50,120,229)\"> Convolución </font>\n",
    "\n",
    "La convolución es un concepto poderoso que forma la base de muchos filtros lineales.\n",
    "\n",
    "Una operación de convolución involucra tres partes: primero tenemos la matriz de entrada, luego tenemos un kernel de convolución, y finalmente tenemos la matriz de salida.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/conv_parts.png\" width=800>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolucionamos la matriz de entrada con el kernel de convolución para obtener la matriz de salida.\n",
    "\n",
    "Imagina colocar el kernel en la esquina superior izquierda de la matriz de entrada donde encaje. Ahora estamos multiplicando los elementos correspondientes de las regiones superpuestas. Por ejemplo, estamos multiplicando 7 por 1, más 2 por 0, menos 1 por 3, más 4 por 1, y así sucesivamente. Entonces, multiplicas los elementos correspondientes y los sumas todos juntos para obtener el resultado, que es el resultado que queremos poner en la matriz de salida.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/step1.png\" width=800>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA**: Notarás que el tamaño de la matriz de salida es ligeramente más pequeño que el de la matriz de entrada, y eso se debe a que estamos calculando los valores de convolución solo en ubicaciones donde el kernel está completamente dentro de la matriz, por lo que se eliminan partes de los bordes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, movemos el kernel un paso hacia la derecha y realizamos la misma operación para obtener el siguiente valor de la matriz de salida, y seguimos haciendo esto hasta que tengamos todos los valores de la matriz de salida. Esta operación se llama convolución.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/step2.png\" width=800>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color: rgb(50,120,229)\"> Convolución en 3D </font>\n",
    "\n",
    "Imagina que tienes una matriz que también tiene profundidad, por lo que es una matriz tridimensional, que también se llama tensor. Queremos calcular la convolución del kernel en esta matriz de entrada. Ahora puedes pensar en esta matriz de entrada como solo una imagen RGB.\n",
    "\n",
    "Para realizar la convolución, el kernel también necesita tener exactamente la misma profundidad.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/3d_conv.png\" width=800>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora imagina que estás moviendo el volumen exactamente de la misma manera que estabas realizando la convolución 2D, pero aquí estás moviendo el cubo completo del kernel de convolución en lugar del cuadrado, y realizas la misma operación y, por supuesto, la salida es exactamente la misma dimensión que antes.\n",
    "\n",
    "En este caso, es una matriz de tres por tres por uno porque estamos multiplicando elementos del volumen y luego sumándolos juntos, y la dimensión de salida no tiene profundidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color: rgb(50,120,229)\"> **¿Cómo se transmite la información en una CNN?** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, en el lado izquierdo, estamos mostrando una imagen de entrada de un solo canal con una dimensión espacial arbitraria. \n",
    "\n",
    "En el centro, tenemos un solo filtro que consiste en un solo kernel con un tamaño espacial de tres por tres, por lo tanto, hay nueve pesos entrenables asociados con este filtro.\n",
    "\n",
    "La profundidad de la imagen de entrada dicta la profundidad del filtro.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/filters.png\" width=600>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al convolucionar el filtro único con una entrada de un solo canal, se obtiene un mapa de activación de un solo canal como salida, ya que el filtro viaja a través de la entrada.\n",
    "\n",
    "En la imagen, calculamos el producto punto del núcleo del filtro con los valores correspondientes en la imagen de entrada. \n",
    "\n",
    "En cada ubicación del filtro, la operación de convolución produce un escalar que se suma a un término de sesgo y luego el resultado se pasa a través de una función de activación.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/conv_flow.png\" width=800>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color: rgb(50,120,229)\"> **¿Qué pasa si incrementamos la profundidad de la imagen de entrada?** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta vez, la entrada representa una imagen en color RGB con tres canales. \n",
    "\n",
    "Aquí hemos optado por usar solo un filtro, pero debido a que la profundidad de la entrada es 3, la profundidad del filtro también debe ser tres, y por lo tanto, el filtro contiene tres núcleos donde cada núcleo tiene nueve pesos entrenables. Por lo tanto, hay un total de 27 pesos entrenables en este filtro más un único término de sesgo, lo que da un total de 28 parámetros entrenables.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/rgb_filter.png\" width=800>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que hemos especificado solo un filtro, la profundidad de nuestra salida sigue siendo uno, lo que significa que producimos solo un mapa de activación de un solo canal. Entonces, en este caso, cuando convolvemos el único filtro con la entrada, la operación de convolución se realiza para cada canal por separado, y luego la suma ponderada de todos los tres canales más un término de sesgo se pasa a través de una función de activación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color: rgb(50,120,229)\"> **¿Qué pasa si agregamos kernels al filtro?** </font>\n",
    "\n",
    "En este próximo ejemplo, volvemos a mirar una imagen de entrada de un solo canal, pero esta vez hemos optado por usar cuatro filtros. \n",
    "\n",
    "Dado que la imagen de entrada es solo un solo canal con una profundidad de 1, cada filtro tiene solo un núcleo. Pero como hay cuatro filtros, la profundidad de la salida es ahora cuatro, por lo que producimos cuatro mapas de activación.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/more_filters.png\" width=800>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color: rgb(50,120,229)\"> **¿Por qué necesitamos más filtros?** </font>\n",
    "\n",
    "La razón de incluir múltiples filtros es que cada filtro aprenderá algo diferente sobre la imagen de entrada. \n",
    "\n",
    "Por ejemplo, un filtro podría aprender a detectar esquinas mientras que otro podría aprender a detectar bordes diagonales. A medida que este proceso continúa, las capas convolucionales más avanzadas en la red aprenderán patrones de nivel superior construidos a partir de estas características de nivel inferior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color: rgb(50,120,229)\"> ¿Qué ve una neurona en una CNN? </font>\n",
    "\n",
    "Observa que cada neurona en el mapa de activación de salida está conectada solo a nueve valores en la imagen de entrada a través de los nueve pesos en el filtro.\n",
    "\n",
    "En otras palabras, cada neurona en la capa de salida solo está mirando una pequeña porción de la imagen de entrada definida por el tamaño espacial del filtro. (El tamaño espacial del filtro es la dimensión del kernel de convolución).\n",
    "\n",
    "Esta región en la imagen de entrada se conoce como el campo receptivo, mostrado en verde y define el área de la imagen de entrada que una neurona en la capa de salida está mirando.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/receptive_field.png\" width=800>\n",
    "</center>\n",
    "\n",
    "\n",
    "Esta es una característica clave de las capas convolucionales, llamada compartición de parámetros, donde usamos el **mismo conjunto de pesos para procesar diferentes partes** de la imagen de entrada.\n",
    "\n",
    "Esto nos permite detectar características y patrones que son **invariantes a la traslación**, a medida que el kernel se mueve a través de la imagen, es decir si un patrón está presente en una parte de la imagen, la red debería ser capaz de detectarlo en cualquier parte de la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color: rgb(50,120,229)\"> Las CNNs aprenden jerarquías de características </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En 2013, un artículo seminal titulado *Visualizing and Understanding Convolutional Networks* arrojó luz sobre por qué las CNNs (redes neuronales convolucionales) funcionan tan bien. Introdujeron una técnica de visualización novedosa que proporciona información sobre la función de las capas intermedias dentro de un modelo de CNN.\n",
    "\n",
    "En el diagrama a continuación, tomamos dos ejemplos del artículo para ilustrar que los filtros en la primera capa aprenden a detectar elementos estructurales básicos como bordes y manchas de color, mientras que las capas más profundas en la red son capaces de detectar estructuras composicionales más complejas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./images/tensorflow-keras-cnn-hierarchical-structure-1024x590.webp\" width=800>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color: rgb(50,120,229)\"> Arquitectura de una CNN </font>\n",
    "\n",
    "Las CNNs están compuestas por una serie de capas, cada una de las cuales realiza una operación específica.\n",
    "\n",
    "En general, podemos dividir en dos bloques principales:\n",
    "\n",
    "1. **Bloque de extracción de características**: Este bloque está compuesto por capas convolucionales y de agrupación. Las capas convolucionales son responsables de extraer características de la imagen de entrada, mientras que las capas de agrupación reducen la dimensionalidad de las características extraídas.\n",
    "\n",
    "2. **Bloque de clasificación**: Este bloque está compuesto por capas densas que clasifican las características extraídas en una o más clases.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/tensorflow-keras-cnn-activation-maps-classifier-intuition-1024x648.webp\" width=800>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
