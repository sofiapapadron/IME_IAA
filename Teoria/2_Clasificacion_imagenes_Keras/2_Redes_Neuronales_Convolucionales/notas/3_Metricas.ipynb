{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:rgb(50,120,229)\"> Métricas de Evaluación para Clasificación </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante el entrenamiento de un modelo, debemos de alguna manera estimar qué tan buena es su calidad. \n",
    "\n",
    "Al conocer qué tan bien está funcionando, podemos compararlo con otros modelos y definir la ruta de mejora o elegir la mejor opción para alguna solución. \n",
    "\n",
    "Para estos propósitos, se inventó un conjunto de métricas de evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 1. Problema de Clasificación </font>\n",
    "\n",
    "Para simplificar la discusión, primero examinamos el caso en el que nuestra clase tiene solo dos clases. \n",
    "\n",
    "Estamos analizando mamogramas y nuestro objetivo es identificar si este mamograma muestra cáncer de mama o no. Dado que estamos buscando cáncer de mama, los mamogramas con cáncer de mama pertenecen a la clase positiva.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/metric_example.png\" width=800>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 2. Matriz de Confusión </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión es una tabla utilizada para describir la precisión de un modelo de clasificación. Las filas de la matriz representan las clases predichas y las columnas representan la verdad fundamental. \n",
    "\n",
    "En algunas matrices de confusión, las filas y las columnas están intercambiadas, así que asegúrate de leer las etiquetas cuando analices una matriz de confusión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El nombre proviene del hecho de que facilita ver si el sistema está confundiendo entre dos clases o etiquetando erróneamente una clase como otra.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/confusion_matrix.png\" width=800>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verás que hay cuatro métricas: verdaderos positivos, verdaderos negativos, falsos positivos y falsos negativos. \n",
    "\n",
    "- **Verdaderos positivos:**. Son casos en los que el algoritmo acierta y la clase es positiva. En nuestro caso, esto significa que el mamograma muestra cáncer de mama y el algoritmo lo identificó correctamente.\n",
    "- **Verdaderos negativos:** Son casos en los que el algoritmo acierta y la clase es negativa. Por lo tanto, el algoritmo identificó correctamente una clase negativa. En nuestro caso, esto significa que el mamograma no muestra cáncer de mama y el algoritmo dice que no hay cáncer de mama.\n",
    "- **Falsos positivos:** Son casos en los que el algoritmo dice que se detectó cáncer de mama, pero en realidad no había cáncer de mama.\n",
    "- **Falsos negativos:** Son casos en los que había cáncer de mama pero el algoritmo falsamente indicó que es negativo, lo que significa que no había cáncer de mama.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 3. Accuracy </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formalmente se define como la proporción de predicciones correctas respecto al total de predicciones.\n",
    "\n",
    "$$ \\text{Accuracy} = \\frac{\\text{Verdaderos Positivos + Verdaderos Negativos}}{\\text{Verdaderos Positivos + Verdaderos Negativos + Falsos Positivos + Falsos Negativos}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50,120,229)\"> **Problema de la Precisión** </font>\n",
    "\n",
    "La principal desventaja de la precisión como métrica es que no funciona muy bien con conjuntos de datos desequilibrados. \n",
    "\n",
    "Por ejemplo, en nuestro caso de mamografías, solo hay cinco casos positivos de cáncer de mama y 95 casos que no tienen cáncer de mama. \n",
    "\n",
    "Si nuestro método clasifica todas las muestras como negativas, lo que significa que predice que todas las muestras no tienen cáncer de mama, los valores en la matriz de confusión serán: verdaderos positivos cero, porque está diciendo que todos son negativos; falsos positivos también cero; verdaderos negativos 95; y falsos negativos 5.\n",
    "\n",
    "Sin embargo, si observas el número de precisión, la precisión es del 95%, es decir, el 95% del tiempo está clasificando las cosas correctamente. Debido a que los datos están desequilibrados y el 95% del tiempo no hay cáncer de mama, **aunque este sea un modelo completamente inútil que no detecta el cáncer de mama, la precisión es del 95%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./images/acurracy.png\" width=1000>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 4. Precision </font>\n",
    "\n",
    "Es la fracción de instancias relevantes entre todas las instancias recuperadas. Nos brinda información sobre el rendimiento de un clasificador con respecto a los falsos positivos.\n",
    "\n",
    "$$ \\text{Precision} = \\frac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos} + \\text{Falsos Positivos}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestro ejemplo, responde a la pregunta: si el resultado es positivo, ¿qué tan seguro podemos estar de que la mamografía contiene una imagen de cáncer de mama? \n",
    "\n",
    "\n",
    "<font style=\"color:rgb(50,120,229)\"> **¿Cuándo usar la precisión negativa?** </font>\n",
    "\n",
    "Si nuestro objetivo principal es minimizar los falsos positivos, entonces necesitamos que la precisión sea lo más cercana posible al 100%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto ocurre frecuentemente en escenarios automotrices o de vigilancia, donde el sistema ayuda al usuario a identificar situaciones como un peatón en la carretera o un robo en el supermercado, y los desencadenantes resultan en alguna acción extrema. Entonces, queremos que los falsos positivos sean realmente pequeños o que la precisión sea muy, muy alta, porque hay un costo muy elevado que pagamos por un falso positivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 5. Recall </font>\n",
    "\n",
    "El \"recall\" es una fracción del total de verdaderos positivos que fueron recuperados. También se le llama tasa de verdaderos positivos.\n",
    "\n",
    "$$ \\text{Recall} = \\frac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos} + \\text{Falsos Negativos}} $$\n",
    "\n",
    "En nuestro ejemplo, supongamos que había n casos de verdaderos positivos en nuestro conjunto de datos. El \"recall\" describe cuántos verdaderos positivos de los totales fue capaz de encontrar el modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, si simplemente clasificamos todo como positivo, tendremos un \"recall\" del 100%, ya que capturaremos todos los casos de las clases positivas. Obviamente, en este caso tendremos una precisión muy baja. Por lo tanto, \"recall\" y precisión se usan juntos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:rgb(50,120,229)\"> **¿Cuándo usar el recall?** </font>\n",
    "\n",
    "Si deseamos enfocarnos en minimizar los falsos negativos, querríamos que nuestro \"recall\" esté lo más cerca posible del 100%, sin que la precisión sea demasiado baja. \n",
    "\n",
    "Por ejemplo, en el diagnóstico médico, es crucial excluir tantos falsos negativos como sea posible. Si una prueba particular está diseñada para detectar una enfermedad y devuelve un resultado negativo para un paciente que realmente la tiene, eso puede tener graves consecuencias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 6. F1 Score </font>\n",
    "\n",
    "Normalmente necesitamos estimar y evaluar tanto la precisión como el \"recall\". El puntaje F1 es una combinación de ambas métricas. Alcanza su mejor valor en uno, lo que significa precisión perfecta y \"recall\" perfecto.\n",
    "\n",
    "En términos de aplicaciones, el puntaje F1 es preferible cuando tienes una clase positiva pequeña. \n",
    "\n",
    "Sin embargo, hay críticas al uso generalizado del puntaje F1, ya que otorga la misma importancia a la precisión y al \"recall\". En la práctica, diferentes tipos de clasificaciones erróneas incurren en diferentes costos dependiendo de la aplicación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 7. Curva de Recibidor de Operación Característica (ROC) </font>\n",
    "\n",
    "Es un gráfico que muestra el rendimiento de un clasificador a medida que se varía su umbral de discriminación. \n",
    "\n",
    "<center>\n",
    "<img src=\"./images/roc.png\" width=500>\n",
    "</center>\n",
    "\n",
    "Los modelos de clasificación típicamente analizan los datos y producen algún valor de confianza de que es un objeto de alguna clase. Entonces, nuestro modelo observará los datos y predecirá, por ejemplo, con un 60% de confianza que hay cáncer de mama en la mamografía. \n",
    "\n",
    "Necesitamos establecer un umbral en este valor para poder establecer un valor de cero o uno para la salida final. Todo lo que esté por encima de él se considerará positivo y todo lo que esté por debajo del umbral se considerará negativo. \n",
    "\n",
    "Dependiendo del algoritmo y la tarea, podemos seleccionar diferentes valores de este umbral.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva ROC ayuda a seleccionar el umbral correcto para nuestro requisito en la tasa de verdaderos positivos y la tasa de falsos positivos.\n",
    "\n",
    "$$ \\text{Tasa de Verdaderos Positivos} = \\frac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos} + \\text{Falsos Negativos}} $$\n",
    "$$ \\text{Tasa de Falsos Positivos} = \\frac{\\text{Falsos Positivos}}{\\text{Falsos Positivos} + \\text{Verdaderos Negativos}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./images/roc_example.png\" width=500>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducir el umbral hace que el modelo clasifique más elementos como positivos, aumentando así el número de verdaderos positivos a expensas de más falsos positivos. De lo contrario, aumentar el umbral reducirá el número de falsos positivos, pero también habrá menos probabilidad de verdaderos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un caso perfecto, existe un umbral que permite al modelo dividir las clases perfectamente. La tasa de verdaderos positivos será igual a uno mientras que la tasa de falsos positivos será cero. La curva ROC resultante será una línea recta pegada a la esquina superior izquierda del gráfico. \n",
    "\n",
    "Por lo tanto, en la práctica, queremos que la curva ROC esté lo más cerca posible de la esquina del gráfico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:rgb(50,120,229)\"> 7.1 Área bajo la curva ROC (AUC) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mide toda el área bidimensional bajo la curva ROC, en algún lugar del cuadrado de 0 0 a 1 1. \n",
    "\n",
    "Cuanto mejor sea el algoritmo de clasificación, mayor será el área bajo la curva ROC. \n",
    "\n",
    "La puntuación típicamente oscila entre 0.5 y 1, y la puntuación de 1 es el caso ideal donde la tasa de verdaderos positivos es 1 y la tasa de falsos positivos es cero, lo que significa que clasificamos correctamente todas las muestras positivas y negativas en el conjunto de datos.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/auc.png\" width=600>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:rgb(50,120,229)\"> Métricas de Evaluación para Clasificación Multiclase </font>\n",
    "\n",
    "En este caso, no tenemos negativos, todas las instancias ahora tienen su propia clase, aunque la clasificación binaria puede ser una tarea útil en la vida real, la clasificación multiclase es mucho más común.\n",
    "\n",
    "\n",
    "Echemos un vistazo a la competencia de clasificación multiclase más popular que hay, se llama ILSVRC, que significa desafío de reconocimiento visual a gran escala de ImageNet.\n",
    "\n",
    "La competencia ImageNet es un desafío muy popular para la clasificación de imágenes con 1000 clases diferentes y más de 1.2 millones de imágenes de entrenamiento. Hay dos métricas de clasificación que utiliza el desafío.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 1. Top-1 Accuracy </font>\n",
    "\n",
    "Se verifica si la clase superior, es decir, aquella que tiene la probabilidad más alta, es la misma que la etiqueta verdadera. Esencialmente, es la métrica de precisión que definimos anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 2. Top-5 Accuracy </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se verifica si la etiqueta objetivo está entre las cinco predicciones principales. \n",
    "\n",
    "Estas cinco predicciones principales son simplemente las cinco clases con las probabilidades más altas. Si eso es cierto, entonces la predicción se considera correcta. En ambos casos, el puntaje total es la proporción de las predicciones correctas divididas por todas las predicciones realizadas por el modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 3. Matriz de Confusión Multiclase </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de que tengamos más de dos clases, aún podemos construir una matriz de confusión que tendrá celdas de n por n, donde n es el número de clases.\n",
    "\n",
    "Veamos un ejemplo extendido donde tenemos cuatro clases: gatos, perros, manzanas y autos. Recuerda que las filas representan la salida predicha y las columnas representan la verdad fundamental.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/confusion_matrix_multi.png\" width=500>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la columna de perros para ver qué tan bien nuestro modelo reconoce a los perros. \n",
    "\n",
    "Tenemos 200 ejemplos de perros en el conjunto de datos. En total, nuestro modelo clasifica correctamente un perro como perro en 168 casos, en 24 casos, sin embargo, equivocadamente dice que es un gato, en seis casos cree que es un auto y en dos casos cree que es una manzana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:rgb(50,120,229)\"> 4. Matriz de Confusión Normalizada </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro conjunto de datos no estaba normalizado. Tenemos 500 gatos, 200 perros, 150 manzanas y solo 50 autos, lo que es 10 veces menos que el número de gatos. \n",
    "\n",
    "Esto hace que los valores absolutos de predicciones correctas e incorrectas no sean muy convenientes de observar, por lo que la gente suele cambiar a la versión normalizada de esta tabla.\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/confusion_matrix_multi_norm.png\" width=500>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver claramente los puntos fuertes y débiles del modelo en una matriz de confusión normalizada perfecta los elementos diagonales deberían ser 100 y todos los demás deberían ser cero. \n",
    "\n",
    "Analizar la desviación de eso proporciona una visión importante sobre la naturaleza de los errores en nuestro modelo. Por ejemplo, nuestro modelo a menudo confunde perros con gatos, y necesitamos pensar cómo solucionarlo.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
