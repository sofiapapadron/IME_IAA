{"cells":[{"cell_type":"markdown","metadata":{"id":"zSx-Cm7bW07k"},"source":["# Clasificación Señas con las manos"]},{"cell_type":"markdown","metadata":{"id":"6iWBftGUW07q"},"source":["En este Notebook entrenaremos una red neuronal para distinguir entre 4 señas diferentes con las manos"]},{"cell_type":"markdown","metadata":{"id":"FJsQ3bhZW07q"},"source":["Utilizaremos un dataset con pocos datos y utilizaremos técnicas adecuadas para este caso."]},{"cell_type":"markdown","metadata":{"id":"5xSTSsmHW07r"},"source":["## Cargar los datos"]},{"cell_type":"markdown","metadata":{"id":"fUdyzgWcW07r"},"source":["Organizaremos las imagenes en la siguiente estructura:\n","\n","- Data\n","  - training\n","    - 1\n","    - 2\n","    - 3\n","    - 4\n","  - validation\n","    - 1\n","    - 2\n","    - 3\n","    - 4"]},{"cell_type":"markdown","metadata":{"id":"n7L1ZsKyW07s"},"source":["Cada carpeta tendra las imagenes correspondientes a esa seña, la etiqueta de la imagen se tomará del nombre de la carpeta."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80VgQHWlW07s","outputId":"ce044113-3189-4910-e7b5-19904600182f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 16 files belonging to 2 classes.\n"]},{"data":{"text/plain":["' val_data = image_dataset_from_directory(\\n    directory=\"data/val\", # Ruta de la carpeta de validación\\n    labels=\"inferred\", # Dejaremos que Keras infiera las etiquetas utilizando el nombre de las carpetas\\n    label_mode=\"categorical\", # Utilizaremos etiquetas categóricas\\n    batch_size=32, # Tamaño del batch\\n    image_size=(24, 224), # Tamaño de las imágenes,\\n    color_mode=\"grayscale\" # Utilizaremos imágenes en escala de grises\\n) '"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["from keras.utils import image_dataset_from_directory\n","\n","train_data = image_dataset_from_directory(\n","    directory=\"data/train\", # Ruta de la carpeta de entrenamiento\n","    labels=\"inferred\", # Dejaremos que Keras infiera las etiquetas utilizando el nombre de las carpetas\n","    label_mode=\"categorical\", # Utilizaremos etiquetas categóricas\n","    batch_size=32, # Tamaño del batch\n","    image_size=(24, 224), # Tamaño de las imágenes,\n","    color_mode=\"rgb\" # Utilizaremos imágenes en escala de grises\n",")\n","\n","#TODO: Crear el conjunto de validación"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-MxHYyu0W07v","outputId":"fdbb9764-c151-4e11-b8c7-11c2adcd37f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["['1', '2']\n"]}],"source":["#Obtenemos las clases para saber el orden de las etiquetas\n","class_names = train_data.class_names\n","print(class_names)"]},{"cell_type":"markdown","metadata":{"id":"95M1pHONW07x"},"source":["## Arquitectura del modelo"]},{"cell_type":"markdown","metadata":{"id":"f_BGFS7gW07y"},"source":["Para la arquitectura del modelo utilizaremos data augmentation y el modelo VGG16"]},{"cell_type":"markdown","metadata":{"id":"NE6Lx3LLW07y"},"source":["Empezaremos agregando la capa de entrada y las capas de preprocesamiento.\n","\n","De preprocesamiento utilizaremos una capa de Rescaling para convertir los valores de la imagen de un rango de 0 a 255 a un rango de 0 a 1."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"__CBfNlyW07z"},"outputs":[],"source":["from keras.layers import Input, Rescaling\n","\n","#TODO Definir capa de entrada\n","\n","#TODO Definir capa de normalización y conectarla a la capa de entrada"]},{"cell_type":"markdown","metadata":{"id":"jVgOqn34W07z"},"source":["Agregue las capas de preprocesamiento que crea adecuadas para el problema."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AyY91-egW070"},"outputs":[],"source":["#TODO importar capas de Data Augmentation\n","\n","#TODO Definir capas de Data Augmentation y concatenarlas"]},{"cell_type":"markdown","metadata":{"id":"a449MXyTW070"},"source":["Ahora importaremos el modelo VGG16 y congelaremos las primeras 5 capas para poder aplicar Fine-Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dq0rCG-QW070"},"outputs":[],"source":["from keras.applications import VGG16\n","\n","#TODO Cargar modelo VGG16 sin las capas densas\n","\n","#TODO Congelar las primeras 5 capas\n"]},{"cell_type":"markdown","metadata":{"id":"9pgIPD44W070"},"source":["Conectaremos el modelo previamente definido con el modelo VGG16"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bDfD2uj8W070"},"outputs":[],"source":["#TODO Conectar modelo previo a VG16"]},{"cell_type":"markdown","metadata":{"id":"Z-B6LF_HW071"},"source":["Por ultimo agregaremos las capas totalmente conectadas para la salida de la red"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rCjqIg9YW071"},"outputs":[],"source":["#TODO Definir capa densa de salida\n","\n","#TODO Definir modelo\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3--BO0UWW071"},"outputs":[],"source":["#TODO Compilar modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nz_JXbVhW073"},"outputs":[],"source":["#TODO Entrenar modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZtXoO9fW073"},"outputs":[],"source":["#TODO Guardar modelo"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}