{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ff48fc",
   "metadata": {
    "id": "42ff48fc"
   },
   "source": [
    "# Ultralytics Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea67ae",
   "metadata": {
    "id": "2cea67ae"
   },
   "source": [
    "Ultralytics Solutions ofrece aplicaciones de vanguardia de los modelos YOLO, brindando soluciones prácticas como conteo de objetos, desenfoque y sistemas de seguridad, mejorando la eficiencia y precisión en diversas industrias. Descubre el poder de YOLO11 para implementaciones prácticas y significativas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7f927",
   "metadata": {},
   "source": [
    "En esta práctica vamos a implementar dos tareas relacionadas con la detección de objetos:\n",
    "\n",
    "- Seguimiento de objetos\n",
    "- Conteo de objetos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f77f3a",
   "metadata": {},
   "source": [
    "Empezaremos haciendo detección en un video, luego haremos seguimiento de los objetos detectados y finalmente contaremos los objetos que pasan por una línea en el video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed78ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8adcfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "#Cargar el modelo pre-entrenado\n",
    "model = YOLO(\"yolo11m.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5b2a4",
   "metadata": {},
   "source": [
    "El modelo YOLO11 ya es capaz de detectar maletas, ya que esta clase está incluida en el conjunto de datos COCO, por lo que orientaremos la práctica a la detección de maletas en un video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload() #Selecciona el archivo de video (Solo 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9683586",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = list(uploaded.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68944bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "suitcase_class = 28 #Clase de la maleta en el dataset de COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "assert cap.isOpened(), f\"Failed to open {video_path}\"\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "#Creamos un video de salida para guardar el video procesado\n",
    "output_path = \"output.mp4\"\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    #Procesar el frame\n",
    "    results = model.predict(frame, classes=[suitcase_class]) #Solo detectar maletas\n",
    "\n",
    "    #Dibujar las detecciones\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    writer.write(annotated_frame)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "cap.release()\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5052a3",
   "metadata": {},
   "source": [
    "**Descarga el video para visualizar los resultados de la práctica:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c75ced",
   "metadata": {},
   "source": [
    "## Seguimiento de objetos\n",
    "\n",
    "El tracking de objetos es una tarea que consiste en seguir un objeto a través de múltiples fotogramas en un video.\n",
    "\n",
    "El seguimiento de objetos me permite obtener la trayectoria de un objeto en un video, lo que puede ser útil para tareas como el conteo de objetos, la detección de comportamientos anómalos, la predicción de trayectorias, entre otros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f8a01",
   "metadata": {},
   "source": [
    "Veamos como se implementa el seguimiento de objetos en un video con YOLO11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7dda6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "assert cap.isOpened(), f\"Failed to open {video_path}\"\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "#Creamos un video de salida para guardar el video procesado\n",
    "output_path = \"output_track.mp4\"\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    #Procesar el frame\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        persist=True, #Seguir las detecciones entre frames\n",
    "        classes=[suitcase_class], #Solo detectar maletas\n",
    "    )\n",
    "\n",
    "    #Dibujar las detecciones\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    writer.write(annotated_frame)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "cap.release()\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98dfc97",
   "metadata": {},
   "source": [
    "Puedes observar que solo es necesario modificar la función predict() a track() para implementar el seguimiento de objetos.\n",
    "\n",
    "En el video observarás que las maletas detectadas ahora incluyen un ID que las identifica a lo largo del video. Si el seguimiento funciona correctamente, las maletas deberían tener el mismo ID en todos los fotogramas en los que aparecen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10cdeed",
   "metadata": {},
   "source": [
    "## Conteo de objetos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb5b808",
   "metadata": {},
   "source": [
    "El conteo de objetos nos permitirá saber cuántos objetos de un tipo específico hay en una determinada región de la imagen o cuántos objetos han pasado por una región de interés.\n",
    "\n",
    "Esta tarea es muy útil en aplicaciones de seguridad, control de tráfico, monitoreo de multitudes, entre otros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f27724c",
   "metadata": {},
   "source": [
    "Ultralytics facilita la implementación de esta tarea con YOLO11 y su módulo de soluciones.\n",
    "\n",
    "Veamos como implementar el conteo de objetos con Ultralytics Solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da3d99",
   "metadata": {},
   "source": [
    "Primero veamos cuanto es el ancho y alto del video que hemos estado utilizando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621f5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Ancho: {width}, Alto: {height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708e7e7",
   "metadata": {},
   "source": [
    "Colocaremos una linea en la parte derecha del video, 800 pixeles antes del borde derecho, para contar las maletas que pasan por esa línea.\n",
    "\n",
    "**Los valores escogidos para la linea son arbitrarios, puedes cambiarlos según tus necesidades.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3203b3d",
   "metadata": {},
   "source": [
    "Vamos a comprobar la posición de la línea en el video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc088ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "line_pt1 = (width - 200, 100)\n",
    "line_pt2 = (width - 200, height - 100)\n",
    "\n",
    "video = cv2.VideoCapture(video_path)\n",
    "\n",
    "assert video.isOpened(), f\"Failed to open {video_path}\"\n",
    "\n",
    "ret, frame = video.read()\n",
    "\n",
    "cv2.line(frame, line_pt1, line_pt2, (0, 255, 0), 2)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e63bd1",
   "metadata": {},
   "source": [
    "Puedes ver que en el código anterior la linea se dibuja en el video y se encuentra en una posición fija por donde pasan las maletas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975c0deb",
   "metadata": {},
   "source": [
    "Vamos a crear el objeto necesario para contar las maletas que pasan por la línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbae9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import solutions\n",
    "\n",
    "counter = solutions.ObjectCounter( #Objeto para contar objetos\n",
    "    classes=[suitcase_class], #Clase a contar, puede ser una lista de clases\n",
    "    region=[line_pt1, line_pt2], #Region de interes en este caso dos puntos que forman una linea\n",
    "    show=True, #Mostrar el video en tiempo real\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "assert cap.isOpened(), f\"Failed to open {video_path}\"\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "#Creamos un video de salida para guardar el video procesado\n",
    "output_path = \"output_counter.mp4\"\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    #Procesar el frame\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        persist=True, #Seguir las detecciones entre frames\n",
    "        classes=[suitcase_class], #Solo detectar maletas\n",
    "    )\n",
    "\n",
    "    annotated_frame = results[0].plot()\n",
    "    \n",
    "    #Contar las maletas\n",
    "    annotated_frame = counter.count(annotated_frame)\n",
    "\n",
    "    writer.write(annotated_frame)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "cap.release()\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b21c9c",
   "metadata": {},
   "source": [
    "Si todo funciona correctamente, deberías ver un contador en la esquina superior izquierda del video que indica cuántas maletas han pasado por la línea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91276a20",
   "metadata": {},
   "source": [
    "## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562ee134",
   "metadata": {},
   "source": [
    "Realiza el conteo de maletas en el segundo video proporcionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c589e4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
