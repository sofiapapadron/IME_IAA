{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color: rgb(50, 120, 229)\"> Implementar una red neuronal en Esp32 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La IA en el borde (Edge AI) es el proceso de ejecutar algoritmos de inteligencia artificial en dispositivos en el borde de Internet u otras redes. El enfoque tradicional para la IA y el aprendizaje automático es usar servidores potentes basados en la nube para realizar el entrenamiento del modelo así como la inferencia (predicciones).\n",
    "\n",
    "Aunque los dispositivos en el borde pueden tener recursos limitados en comparación con sus homólogos basados en la nube, ofrecen una reducción en el uso del ancho de banda, menor latencia y una mayor privacidad de los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color: rgb(50, 120, 229)\"> Objectivos </font>\n",
    "\n",
    "En esta práctica vamos a implementar una red neuronal en un ESP32, un microcontrolador de bajo costo y bajo consumo de energía. La red neuronal que vamos a implementar es un clasificador de poses de la mano, que puede clasificar entre 5 poses diferentes (arriba, abajo, izquierda, derecha y centro).\n",
    "\n",
    "Entrenaremos el modelo utilizando los datos del sensor MPU6050 adquiridos en la práctica anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color: rgb(50, 120, 229)\"> 1.1 Importar los datos </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a importar los datos que adquirimos en la práctica anterior utilizando la librería pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acelX</th>\n",
       "      <th>acelY</th>\n",
       "      <th>acelZ</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>1.23</td>\n",
       "      <td>9.25</td>\n",
       "      <td>2.98</td>\n",
       "      <td>RIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>9.59</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>DOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.26</td>\n",
       "      <td>8.10</td>\n",
       "      <td>5.38</td>\n",
       "      <td>RIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>1.87</td>\n",
       "      <td>9.53</td>\n",
       "      <td>1.24</td>\n",
       "      <td>RIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>0.35</td>\n",
       "      <td>-9.76</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>LEFT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acelX  acelY  acelZ  output\n",
       "688    1.23   9.25   2.98   RIGHT\n",
       "1601   9.59  -2.26  -1.41    DOWN\n",
       "492    0.26   8.10   5.38   RIGHT\n",
       "430    1.87   9.53   1.24   RIGHT\n",
       "1381   0.35  -9.76  -1.97    LEFT"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"./data/datos_mpu6050.csv\")#TODO: Cargar el dataset usando pandas\n",
    "\n",
    "#Mezclamos los datos para que no haya sesgo\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color: rgb(50, 120, 229)\"> 1.2 Preprocesar los datos </font>\n",
    "\n",
    "Vamos a realizar los siguientes pasos para preprocesar los datos:\n",
    "\n",
    "- Separar los datos en entrada y salida.\n",
    "- Codificar las etiquetas de salida aplicando one-hot encoding.\n",
    "- Separar los datos en entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acelX</th>\n",
       "      <th>acelY</th>\n",
       "      <th>acelZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>1.23</td>\n",
       "      <td>9.25</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>9.59</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>-1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.26</td>\n",
       "      <td>8.10</td>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>1.87</td>\n",
       "      <td>9.53</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>0.35</td>\n",
       "      <td>-9.76</td>\n",
       "      <td>-1.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acelX  acelY  acelZ\n",
       "688    1.23   9.25   2.98\n",
       "1601   9.59  -2.26  -1.41\n",
       "492    0.26   8.10   5.38\n",
       "430    1.87   9.53   1.24\n",
       "1381   0.35  -9.76  -1.97"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Crear un dataframe con las columnas acelX, acelY y acelZ, guardalo en la variable X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "688      RIGHT\n",
       "1601      DOWN\n",
       "492      RIGHT\n",
       "430      RIGHT\n",
       "1381      LEFT\n",
       "Name: output, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Crear un dataframe con la columna output, guardalo en la variable y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para codificar las etiquetas de salida vamos a utilizar la función `get_dummies` de pandas.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "encoded_labels = pd.get_dummies(labels, dtype=dtype)\n",
    "```\n",
    "\n",
    "- `labels`: es un arreglo de numpy o una serie de pandas con las etiquetas de salida.\n",
    "- `dtype`: es el tipo de dato de las columnas de la matriz de salida (int, float, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOWN</th>\n",
       "      <th>IDLE</th>\n",
       "      <th>LEFT</th>\n",
       "      <th>RIGHT</th>\n",
       "      <th>TOP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DOWN  IDLE  LEFT  RIGHT  TOP\n",
       "688    0.0   0.0   0.0    1.0  0.0\n",
       "1601   1.0   0.0   0.0    0.0  0.0\n",
       "492    0.0   0.0   0.0    1.0  0.0\n",
       "430    0.0   0.0   0.0    1.0  0.0\n",
       "1381   0.0   0.0   1.0    0.0  0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Convertir la columna y en un one-hot encoding usando pd.get_dummies, recuerda especificar el tipo de dato como float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un paso muy importante es separar los datos en entrenamiento y prueba, esto nos permitirá evaluar el modelo en datos que no ha visto durante el entrenamiento.\n",
    "\n",
    "Realizaremos la separación utilizando la función `sample` de pandas.\n",
    "\n",
    "```python\n",
    "train_data = data.sample(frac=0.8)\n",
    "test_data = data.drop(train_data.index)\n",
    "```\n",
    "\n",
    "- **frac**: es el porcentaje de datos que se utilizarán para entrenamiento. En este caso, el 80% de los datos se utilizarán para entrenamiento.\n",
    "\n",
    "- **drop**: Elimina las filas con los índices especificados, en este caso, eliminamos las filas que se utilizaron para entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Dividir los datos en entrenamiento y prueba usando X.sample y y.sample\n",
    "# Guarda los datos de entrenamiento en las variables X_train y y_train\n",
    "# Guarda los datos de prueba en las variables X_test y y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, vamos a normalizar los datos de entrada utilizando la librería `pandas`.\n",
    "\n",
    "La normalización que vamos a utilizar se conoce como `estandarización` y se calcula utilizando la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "X_{std} = \\frac{X - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $X_{std}$: es el valor normalizado.\n",
    "- $X$: es el valor original.\n",
    "- $\\mu$: es la media de los datos.\n",
    "- $\\sigma$: es la desviación estándar de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La estandarización se aplica a todos los datos, pero el cálculo de la media y la desviación estándar se realiza solo en los datos de entrenamiento.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN: [ 1.56263941 -0.25539653  2.91141264]\n",
      "STD: [6.08261283 5.60008756 4.26860499]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"MEAN: {mean.values}\")\n",
    "print(f\"STD: {std.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Los valores obtenidos en la celda anterior se utilizaran para normalizar los datos en la ESP32.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acelX</th>\n",
       "      <th>acelY</th>\n",
       "      <th>acelZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>-1.795715</td>\n",
       "      <td>-0.002608</td>\n",
       "      <td>-0.363447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>1.240809</td>\n",
       "      <td>0.042034</td>\n",
       "      <td>-1.808884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>1.087914</td>\n",
       "      <td>0.054534</td>\n",
       "      <td>0.763385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1.385484</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>-1.270067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-0.008654</td>\n",
       "      <td>-0.024036</td>\n",
       "      <td>1.627836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         acelX     acelY     acelZ\n",
       "787  -1.795715 -0.002608 -0.363447\n",
       "1649  1.240809  0.042034 -1.808884\n",
       "1508  1.087914  0.054534  0.763385\n",
       "1606  1.385484  0.004535 -1.270067\n",
       "116  -0.008654 -0.024036  1.627836"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keras ya proporciona una capa de normalización que se puede utilizar en la red neuronal, no la utilizamos en este caso por que TF Lite Micro aun no soporta esta capa de Keras.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta este punto, hemos realizado todos los pasos necesarios para preprocesar los datos, pero tenemos los datos en un formato de pandas, necesitamos convertirlos a un formato que pueda ser utilizado por Keras.\n",
    "\n",
    "Vamos a convertir los datos a un arreglo de numpy utilizando el atributo `values`.\n",
    "\n",
    "```python\n",
    "train_data = train_data.values\n",
    "test_data = test_data.values\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Convertir los datos de entrenamiento y prueba a un arreglo de numpy usando .values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color: rgb(50, 120, 229)\"> 2. Crear el modelo </font>\n",
    "\n",
    "Ya que hemos preprocesado los datos, vamos a crear el modelo de la red neuronal.\n",
    "\n",
    "El modelo que vamos a crear es un modelo secuencial, que consta de las siguientes capas:\n",
    "\n",
    "- Capa de entrada.\n",
    "- Capa densa con 8 neuronas y función de activación ReLU.\n",
    "- Capa de salida con 5 neuronas y función de activación softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(3,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "```\n",
    "\n",
    "- `Input`: Capa de entrada.\n",
    "- `Dense`: Capa densa.\n",
    "- `shape`: Forma de los datos de entrada.\n",
    "- `activation`: Función de activación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m45\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77</span> (308.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m77\u001b[0m (308.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77</span> (308.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m77\u001b[0m (308.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "#TODO: Crear un modelo secuencial\n",
    "\n",
    "#TODO: Agregar una capa de entrada con 3 neuronas, una para cada columna de X\n",
    "\n",
    "#TODO: Agregar una capa densa con 8 neuronas y activación relu\n",
    "\n",
    "#TODO: Agregar una capa densa con 5 neuronas y activación softmax, 5 neuronas porque tenemos 5 clases en la salida\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de definir la arquitectura de la red, vamos a compilar el modelo.\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "- `optimizer`: Optimizador.\n",
    "- `loss`: Función de pérdida, en este caso, utilizamos la entropía cruzada categórica porque estamos realizando una clasificación multiclase.\n",
    "- `metrics`: Métricas que se utilizarán para evaluar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, vamos a entrenar el modelo.\n",
    "\n",
    "```python\n",
    "model.fit(train_data, train_labels, epochs=20, validation_data=(test_data, test_labels))\n",
    "```\n",
    "\n",
    "- `epochs`: Número de épocas.\n",
    "- `validation_data`: Datos de validación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5313 - loss: 1.3870 - val_accuracy: 0.6559 - val_loss: 1.2495\n",
      "Epoch 2/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.6948 - loss: 1.2283 - val_accuracy: 0.7921 - val_loss: 1.0904\n",
      "Epoch 3/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.7938 - loss: 1.0721 - val_accuracy: 0.8020 - val_loss: 0.9314\n",
      "Epoch 4/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.8143 - loss: 0.9032 - val_accuracy: 0.8020 - val_loss: 0.7790\n",
      "Epoch 5/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.8444 - loss: 0.7254 - val_accuracy: 0.8119 - val_loss: 0.6398\n",
      "Epoch 6/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.8638 - loss: 0.5930 - val_accuracy: 0.9431 - val_loss: 0.5177\n",
      "Epoch 7/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.9813 - loss: 0.4666 - val_accuracy: 0.9728 - val_loss: 0.4140\n",
      "Epoch 8/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9920 - loss: 0.3772 - val_accuracy: 0.9950 - val_loss: 0.3320\n",
      "Epoch 9/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.9934 - loss: 0.3013 - val_accuracy: 0.9975 - val_loss: 0.2678\n",
      "Epoch 10/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 1.0000 - loss: 0.2428 - val_accuracy: 1.0000 - val_loss: 0.2151\n",
      "Epoch 11/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 0.1909 - val_accuracy: 1.0000 - val_loss: 0.1737\n",
      "Epoch 12/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 1.0000 - loss: 0.1573 - val_accuracy: 1.0000 - val_loss: 0.1418\n",
      "Epoch 13/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 1.0000 - loss: 0.1278 - val_accuracy: 1.0000 - val_loss: 0.1173\n",
      "Epoch 14/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 0.1070 - val_accuracy: 1.0000 - val_loss: 0.0977\n",
      "Epoch 15/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 1.0000 - loss: 0.0870 - val_accuracy: 1.0000 - val_loss: 0.0826\n",
      "Epoch 16/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 1.0000 - loss: 0.0763 - val_accuracy: 1.0000 - val_loss: 0.0708\n",
      "Epoch 17/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 1.0000 - loss: 0.0645 - val_accuracy: 1.0000 - val_loss: 0.0614\n",
      "Epoch 18/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 1.0000 - loss: 0.0552 - val_accuracy: 1.0000 - val_loss: 0.0536\n",
      "Epoch 19/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 1.0000 - loss: 0.0495 - val_accuracy: 1.0000 - val_loss: 0.0472\n",
      "Epoch 20/20\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0426 - val_accuracy: 1.0000 - val_loss: 0.0419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x161086bd850>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Si el modelo se entrena correctamente debes de obtener un valor de perdida bajo y un valor de precisión alto, ádemas de que la precisión en los datos de validación debe ser similar a la precisión en los datos de entrenamiento.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color: rgb(50, 120, 229)\"> 3. Convertir el modelo a TensorFlow Lite </font>\n",
    "\n",
    "Una vez que hemos entrenado el modelo, vamos a convertirlo a TensorFlow Lite para poder ejecutarlo en la ESP32.\n",
    "\n",
    "Para convertir el modelo a TensorFlow Lite, vamos a utilizar la función `TFLiteConverter` de TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\97ped\\AppData\\Local\\Temp\\tmp8ociq3vk\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\97ped\\AppData\\Local\\Temp\\tmp8ociq3vk\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\97ped\\AppData\\Local\\Temp\\tmp8ociq3vk'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 3), dtype=tf.float32, name='keras_tensor_4')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1516282288400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516282287056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516282287824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1516282289360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import lite as tflite\n",
    "\n",
    "model_name = \"mpu6050_model\" #Nombre del archivo donde se guardará el modelo\n",
    "\n",
    "converter = tflite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert() #Convertimos el modelo a un modelo tflite\n",
    "\n",
    "with open(f\"{model_name}.tflite\", 'wb') as f: #Abrimos un archivo en modo escritura binaria\n",
    "    f.write(tflite_model) #Guardamos el modelo en un archivo llamado model.tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchas plataformas de microcontroladores no tienen soporte para TensorFlow Lite. La forma más sencilla de ejecutar un modelo de TensorFlow Lite en un microcontrolador es convertirlo a una matriz de bytes y ejecutarlo en el microcontrolador.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tflite_to_array(model_data, model_name):\n",
    "    c_str = \"\"\n",
    "\n",
    "    #Creamos las cabeceras del archivo\n",
    "    c_str += f\"#ifndef {model_name.upper()}_H\\n\"\n",
    "    c_str += f\"#define {model_name.upper()}_H\\n\\n\"\n",
    "\n",
    "    #Agregamos una variable con el tamaño del modelo\n",
    "    c_str += f\"const unsigned int {model_name}_len = {len(model_data)};\\n\\n\"\n",
    "\n",
    "    #Agregamos el modelo como un arreglo de bytes\n",
    "    c_str += f\"const unsigned char {model_name}[] = {{\\n\"\n",
    "\n",
    "    for i, byte in enumerate(model_data):\n",
    "        c_str += f\"0x{byte:02X},\"\n",
    "        if (i + 1) % 12 == 0:\n",
    "            c_str += \"\\n\"\n",
    "\n",
    "    c_str += \"};\\n\\n\"\n",
    "\n",
    "    #Cerramos las cabeceras del archivo\n",
    "    c_str += f\"#endif // {model_name.upper()}_H\\n\"\n",
    "\n",
    "    return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_array = tflite_to_array(tflite_model, model_name)\n",
    "\n",
    "with open(f\"{model_name}.h\", 'w') as f:\n",
    "    f.write(model_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
